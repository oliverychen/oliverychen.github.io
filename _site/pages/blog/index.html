<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title></title>

<meta name="keywords" content="about, Jekyll, theme, responsive">



<!-- Twitter Cards -->
<meta name="twitter:title" content="">




<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://oliverychen.github.io/images/default-thumb.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="">

<meta property="og:url" content="http://oliverychen.github.io/pages/blog/">
<meta property="og:site_name" content="">

<meta property="og:image" content="http://oliverychen.github.io/images/default-thumb.png">






<link rel="canonical" href="http://oliverychen.github.io/pages/blog/">
<link href="http://oliverychen.github.io/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://oliverychen.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://oliverychen.github.io/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://oliverychen.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://oliverychen.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://oliverychen.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://oliverychen.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://oliverychen.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://oliverychen.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://oliverychen.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://oliverychen.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="page">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://oliverychen.github.io/"></a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				        
				    
				    <li><a href="http://oliverychen.github.io/pages/home/" >Home</a></li>
				
				    
				        
				    
				    <li><a href="http://oliverychen.github.io/pages/blog/" >Research Blog</a></li>
				
				    
				        
				    
				    <li><a href="http://oliverychen.github.io/pages/research/" >Slides</a></li>
				
				    
				        
				    
				    <li><a href="http://oliverychen.github.io/pages/publications/" >Works</a></li>
				
				    
				        
				    
				    <li><a href="http://oliverychen.github.io/pages/personal/" >Personal</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    


<div itemscope itemtype="http://schema.org/Person">


	<img src="http://oliverychen.github.io/images/OLIVER.JPG" class="bio-photo" alt="Oliver Y. Chén bio photo">


  <h3 itemprop="name">Oliver Y. Chén</h3>
  <p></p>
  <a href="mailto:olivery.chen@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  
  
  
  
  
  
  
  <a href="http://github.com/oliverychen" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="page">
    <h1></h1>
    <div class="article-wrap">
      <meta charset="utf-8" />

<title></title>

<meta name="keywords" content="about, Jekyll, theme, responsive" />

<!-- Twitter Cards -->
<meta name="twitter:title" content="" />

<meta name="twitter:card" content="summary" />

<meta name="twitter:image" content="http://oliverychen.github.io/images/default-thumb.png" />

<!-- Open Graph -->
<meta property="og:locale" content="en_US" />

<meta property="og:type" content="article" />

<meta property="og:title" content="" />

<meta property="og:url" content="http://oliverychen.github.io/pages/blog/" />

<meta property="og:site_name" content="" />

<meta property="og:image" content="http://oliverychen.github.io/images/default-thumb.png" />

<link rel="canonical" href="http://oliverychen.github.io/pages/blog/" />

<link href="http://oliverychen.github.io/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed" />

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True" />

<meta name="MobileOptimized" content="320" />

<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<!-- For all browsers -->
<link rel="stylesheet" href="http://oliverychen.github.io/assets/css/main.css" />

<meta http-equiv="cleartype" content="on" />

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://oliverychen.github.io/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://oliverychen.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://oliverychen.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href="//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic" rel="stylesheet" type="text/css" />

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://oliverychen.github.io/favicon.ico" />

<!-- 32x32 -->
<link rel="shortcut icon" href="http://oliverychen.github.io/favicon.png" />

<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://oliverychen.github.io/images/apple-touch-icon-precomposed.png" />

<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://oliverychen.github.io/images/apple-touch-icon-72x72-precomposed.png" />

<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://oliverychen.github.io/images/apple-touch-icon-114x114-precomposed.png" />

<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://oliverychen.github.io/images/apple-touch-icon-144x144-precomposed.png" />

<p><img src="/images/data_speak.jpg" alt="x" />
<br /></p>

<h1 id="welcome-to-the-span-stylecolor1122ccbrain-whispersspan-blog-where-the-brain-whispers">Welcome to the <span style="color:#1122CC">Brain Whispers</span> blog, where the brain whispers.</h1>
<hr />

<!-- blog Top -->

<h2> Trouver la Lumière Dans L'obscurité
</h2>

<p>Last updated: Dec 11, 2016</p>
<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Louis_XIV_of_France.jpg" alt="HTML5 Icon" style="width:250px;" />
        <br />
        Louis XIV of France (1638 – 1715)
        <br />
        by Hyacinthe Rigaud (1701)
        <br />
        
    </a>
</div>
</center>

<div style="background-color:black; color:white; padding:20px;">
<p>￼
The light shines in the darkness, and the darkness has not overcome it.</p>

- <i>John 1:5</i> (English Standard Version)
<br />

</div>
<p><br />
I am going to write about stability analysis regarding clustering algorithms (which are commonly used investigating brain data): grouping observations (brain measurements) into different clusters (e.g. observation 1 belongs to Cluster A, observation 2 belongs to Cluster B, etc.) based upon their (intrinsic) characteristics or features. But why do I quote <i>John 1:5</i>, include a photo of Louis XIV, and talk about light and darkness?</p>

<p><br />
Because clustering analysis and the challenge thereof remind us of two things. One is that clustering analysis, or any unsupervised learning approach, is to search in darkness for light, as we do not know the true groups, while, very likely, there are true clusters (light) to which they belong, where the member of one group share more similar intrinsic features than non-members; the other is <i>John 1:5</i>, that indeed there is true group information underlying, yet we, living in the darkness, have not found a reliable algorithm (candles that are affordable and durable) to uncover the turth, or have unfortunately found one that miscasts the truth. The first descibes the goal of clustering analysis, and the second summarizes one of its difficulties.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Paris.png" alt="HTML5 Icon" style="width:500px;" />
        <br />
        Source: <i>How Paris Became Paris: The Invention of the Modern City</i> (p.136)
        <br />
        by Joan Elizabeth DeJean
        <br />
        
    </a>
</div>
</center>

<h5>I. Prologue: La Ville Lumière</h5>
<p>Today, the city of Paris is referred to as <i>la Ville Lumière</i> (the City of Light) because of its role during <i>le Siècle des Lumières</i> (lit. the Century of Light, or the Age of Enlightenment). But it literally refers to, according to Wikipedia, the fact that Paris was one of the first European cities to adopt gas street lighting in the 1860s.</p>

<p><br />
However, after some further digging, the street lighting in Paris started with candles, rather than gas, dated back to as early as 1666, as according to the Oct. 29 issue of Gazette (by Charles Robinet), it said that “it is now as bright as night as at high noon.” Large candles, “designed to burn for eight to ten hours” putting in 2,736 lanterns composed of glass panels were used. This was initiated by Gabriel Nicolas de la Reynie and supported by Jean-Baptiste Colbert, minister to the King, and the King, Louis XIV, upon whose death in 1715 began the Age of Enlightenment. The introduction of street lighting turned Paris evening from darkness to brightness, and entailed (partially) the Enlightenment. It reminds me of clustering analysis, where the groups of observations are living in the darkness and are awaiting to be unvealed via fast and effective algorithms (affordable and durable candles).</p>

<p><br />
Hence, I shamelessly adopt the above as my prologue.</p>

<h5>II. Definitions</h5>

<p><img center="" src="http://latex.codecogs.com/gif.latex? \bold{X} = (X_1, X_2, \ldots, X_n)  " border="0" />, where <img center="" src="http://latex.codecogs.com/gif.latex? X_i, i = 1, 2, \ldots  " border="0" /> can be multidimensional, defines <b>data</b> on which a clustering analysis are to be implemented: For example, <img center="" src="http://latex.codecogs.com/gif.latex? X_i " border="0" /> can be vectorized connectivity matrix for subject <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" />.
<br />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}_k " border="0" /> is a (clustering) algorithm that is applied on <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}  " border="0" /> and that renders <img center="" src="http://latex.codecogs.com/gif.latex? k " border="0" /> groups (clusters) <img center="" src="http://latex.codecogs.com/gif.latex? \bold{Y} = (Y_1, Y_2, \ldots, Y_n)  " border="0" />, where <img center="" src="http://latex.codecogs.com/gif.latex? Y_i \in \{1, 2, \ldots, k \}, i = 1, 2, \ldots  " border="0" /> Technically, <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}_k " border="0" /> is a map such that <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}_k: Y = \mathcal{A}_k (\bold{X}). " border="0" />
<br />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex? \phi " border="0" /> is a classifier baded upon the above operation engendering <img center="" src="http://latex.codecogs.com/gif.latex? (\bold{X}, \bold{Y}) " border="0" />. In other words, <img center="" src="http://latex.codecogs.com/gif.latex? \phi (\cdot) = \phi_{\bold{X}, \bold{Y}} (\cdot). " border="0" /> In the case of simple linear regression, <img center="" src="http://latex.codecogs.com/gif.latex? \phi_{\bold{X}, \bold{Y}} = \hat{\beta} (\bold{X}, \bold{Y}) = (\bold{X}^{\prime}\bold{X})^{-1}\bold{Y}. " border="0" />
<br />
<br />
The classifier <img center="" src="http://latex.codecogs.com/gif.latex? \phi " border="0" /> appllied to a new dataset <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}^{\prime} " border="0" />  will render clustering of <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}^{\prime} " border="0" /> <b>based upon <img center="" src="http://latex.codecogs.com/gif.latex? (\bold{X}, \bold{Y}) " border="0" /> </b>. The algorithm <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}_k " border="0" /> appllied to <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}^{\prime} " border="0" /> will generate clustering of <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}^{\prime} " border="0" /> (namely <img center="" src="http://latex.codecogs.com/gif.latex? \bold{Y}^{\prime} = \mathcal{A}_k (\bold{X}^{\prime}) " border="0" />) <b>based upon <img center="" src="http://latex.codecogs.com/gif.latex? \bold{X}^{\prime} " border="0" /></b>. <img center="" src="http://latex.codecogs.com/gif.latex? \phi(\bold{X}^{\prime}) " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}_k (\bold{X}^{\prime}) " border="0" /> could be different. 
<br />
<br />
Hence, we define the normalized Hamming distance to describe such a discrepancy:
<img center="" src="http://latex.codecogs.com/gif.latex? d(\phi(\bold{X}^{\prime}), \mathcal{A}_k (\bold{X}^{\prime})) :=  \dfrac{1}{n}\sum_{i=1}^{n} 1_{\{ \phi(X_i^{\prime}) \neq \mathcal{A}_k (X_i^{\prime})\}} " border="0" />.
<br />
<br />
But, incorrect discrepancy may be introduced as follows: for <img center="" src="http://latex.codecogs.com/gif.latex? k=2 " border="0" />, if one algorithm groups the first part all 1’s and the second part all 2’s, and another algorithm clusters the first part all 2’s and the second all 1’s, the two algorithms generate essentially the same result. To avoid this, define (see J. DeJean (2014))</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
d_{\mathcal{G}_k} (\phi(\bold{X}^{\prime}), \mathcal{A}_k (\bold{X}^{\prime})) := 
\min_{\pi \in {\mathcal{G}_k}} 
\dfrac{1}{n}
\sum_{i=1}^{n} 1_{
\bigg\{ \pi \big(\phi(X_i^{\prime})\big) \neq \mathcal{A}_k (X_i^{\prime}) 
\bigg \}
}
" border="0" />,
</center>
<p>where <img center="" src="http://latex.codecogs.com/gif.latex? \pi " border="0" /> is a permutation operation.</p>

<h5>III. Stability Procedure of Clustering Analysis</h5>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Procedure.jpg" alt="HTML5 Icon" style="width:500px;" />
        <br />
        Adapted from Table 1. of T. Lange et al (2004)
    </a>
</div>
</center>

<h5>References:</h5>
<p>[1] J. DeJean (2014) How Paris Became Paris: The Invention of the Modern City;
<br />
[2] T. Lange et al (2004) Stability-based validation of clustering solutions.</p>

<hr />

<!-- Break -->

<h2> An ICA by Any Other Name Would Smell as Sweet: Group ICA
</h2>

<p>Last updated: Nov 2, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼What's in a name? that which we call a rose
<br />
By any other name would smell as sweet.</p>

- <i>Romeo and Juliet</i>: II, ii, 1-2
</div>

<p><br />
Please refresh your browser if you have trouble viewing the slides; alternatively, please view it <a href="http://www.brainmapping.org/NITP/images/Summer2011Slides/2011_UCLA_GroupICA.pdf">here</a>.</p>
<center>
<iframe src="http://docs.google.com/gview?url=http://www.brainmapping.org/NITP/images/Summer2011Slides/2011_UCLA_GroupICA.pdf&amp;embedded=true" style="width:500px; height:400px;" frameborder="0"></iframe>
</center>
<p><br /></p>

<p><br />
<strong>Further Reading</strong>
<br />
<br />
Calhoun et al (2009). <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2651152/">A review of group ICA for fMRI data and ICA for joint inference of imaging, genetic, and ERP data</a>
<br /></p>

<hr />

<h2> On Rejections
</h2>

<p>Last updated: Oct 26, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼
Success consists of going from failure to failure without loss of enthusiasm.</p>

- Sir Winston Leonard Spencer-Churchill
<br />

</div>

<p><br />
Here are two fascinating resouces regarding rejections. <a href="http://bulletin.imstat.org/2013/08/1562/">Rejection Pursuit</a> is an article written by Xiao-Li MENG, Dean of Art of Science at Harvard, regarding a paper (now published) that had been rejected for a decade; and <a href="http://bsc.harvard.edu/files/bsc/files/bsc_pub_-_reflections_on_rejections_2nd_edition.pdf">Reflections on Rejections</a> includes short stories told by now established leaders in art, science, medicine, and law about their rejections - which have now been gathered into a course on rejections. All these remind me of countless rejections that I had received (and surely do foresee, now with a thankful heart, to have more).
<br />
<br />
The readings have helped me a great deal; I hope they could help you, too. And
<br />
<br />
<span style="background-color: lightgrey"> <i>Never give in, never give in, never, never, never, never.
<br />
<br />
- Sir Winston Leonard Spencer-Churchill </i></span></p>

<hr />

<!-- blog XII -->

<h2> Derivation of the Free Energy Principle
</h2>

<p>Last updated: Oct 14, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼Now go we in content
<br />
To liberty, and not to banishment.</p>

- <i>As You Like It</i>: Act 1, Scene 3
</div>

<p><br />
Below is a brief derivation of the Free Energy Principle (which shows that Eq (2) in  <a href="http://www.fil.ion.ucl.ac.uk/~karl/A%20free%20energy%20principle%20for%20the%20brain.pdf ">Friston et al (2006) </a>) has a minor typo); excuse my ignorance, though, if this is simply my mistake.
<br />
<br />
Let us begin by recalling the free energy as:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
F(y, \lambda) = - \int q(v; \lambda) \ln \frac{p(y,v)}{q(v;\lambda)} dv
" border="0" />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex?
 = - \int q(v; \lambda) p(y,v) dv + \int q(v; \lambda) q(y,v) dv,   
" border="0" />
</center>
<p><br />
which gives Eq (1) in <a href="http://www.fil.ion.ucl.ac.uk/~karl/A%20free%20energy%20principle%20for%20the%20brain.pdf ">Friston et al (2006) </a>).
<br />
<br />
Keeping writing, we have</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\bigg\{ 
- \int q(v; \lambda) \ln p(v|y)p(y) dv + 
\int q(v; \lambda) \ln q(v;\lambda) dv
\bigg \}
" border="0" />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex?
 = \bigg\{
- \int q(v; \lambda) \ln p(v|y) dv 
- \int q(v; \lambda) \ln p(y) dv 
 \bigg \}
 + \int q (v;\lambda) \ln q(v;\lambda) dv  
" border="0" />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex?
 = \bigg\{
- \int q(v; \lambda) \ln p(v|y) dv 
- \int q(v; \lambda) \ln p(y) dv 
 \bigg \}
 + D \bigg(
q(v;\lambda) \parallel p(v|y)
 \bigg)  
 + \int q(v; \lambda) \ln p(v|y) dv
" border="0" />
<br />
<img center="" src="http://latex.codecogs.com/gif.latex?
 =
- \int q(v; \lambda) \ln p(y) dv 
 
 + D \bigg(
q(v;\lambda) \parallel p(v|y)
 \bigg),
" border="0" />
</center>
<p><br />
which gives Eq (2) in <a href="http://www.fil.ion.ucl.ac.uk/~karl/A%20free%20energy%20principle%20for%20the%20brain.pdf ">Friston et al (2006) </a>), wherein the first term slightly differ.</p>

<hr />

<!-- blog XI -->

<h2> Predictive Functional Connectivity 
</h2>

<p>Last updated: Oct 13, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼An unsophisticated forecaster uses statistics as a drunken man uses lamp-posts - for support rather than for illumination.</p>

– Andrew Lang <br />
<br />

<p>What is creative is the seeking of perfection - and not attaining it.</p>

- Semir Zeki 
</div>

<h5>1.1 Vector Autoregressive(VAR) Process</h5>

<p>Consider <img center="" src="http://latex.codecogs.com/gif.latex? \{ \mathbf{X}_i \in \mathbb{R}^d \}_{i \in \mathbb{Z}} " border="0" /> as a stationalry process satisfying the VAR model:</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\mathbf{X}_i = \mathbf{A} \mathbf{X}_{i-1} + \mathbf{\epsilon}_i, \forall i \in \mathbb{R},
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? \{ \mathbf{\epsilon}_i \in \mathbb{R}^d \}_{i \in \mathbb{Z}} " border="0" /> is a sequence of i.i.d. random vectors.</p>

<h5>1.2 <img center="" src="http://latex.codecogs.com/gif.latex?
\alpha
" border="0" />-mixing Process</h5>

<p>Definition (Richard C. Bradley (2015s)). Let <img center="" src="http://latex.codecogs.com/gif.latex? (\Omega, \mathcal{F}, \mathbb{P}) " border="0" /> be a <i>probability space</i> and <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{A}, \mathcal{B} " border="0" /> be two <img center="" src="http://latex.codecogs.com/gif.latex? \sigma " border="0" />-fields. The <img center="" src="http://latex.codecogs.com/gif.latex? \alpha " border="0" /> dependency measure is defined as follows.</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\alpha(\mathcal{A}, \mathcal{B}): = \sup _{A \in \mathcal{A}, B \in \mathcal{B}}
\left\vert
\mathbb{P} (A \cap B) - \mathbb{P}(A) \mathbb{P}(B)
\right \vert
" border="0" />
    </center>

<p>Let <img center="" src="http://latex.codecogs.com/gif.latex? \{ \mathbf{X}_i \} _{i \in \mathbb{Z}} " border="0" /> be a <i>stochastic process</i>. For <img center="" src="http://latex.codecogs.com/gif.latex? -\infty \leq M \leq N \leq \infty " border="0" />, define <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{F}_ " border="0" />, define <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{F}_M^N := \sigma \{  \mathbf{X}_i: N \leq i \leq M, i \in \mathbb{R}    \} " border="0" /> as a sigma-field generated by <img center="" src="http://latex.codecogs.com/gif.latex? \{\mathbf{X}_i: N \leq i \leq M, i \in \mathbb{R} \} " border="0" />. For any <img center="" src="http://latex.codecogs.com/gif.latex? i \geq 1 " border="0" />, we define the <img center="" src="http://latex.codecogs.com/gif.latex? \alpha " border="0" />-mixing coefficients as</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\alpha(i) := \sup_{m \in \mathbb{Z}} \alpha \big( \mathcal{F}_{-\infty}^m, \mathcal{F}_{m+i}^\infty \big).
" border="0" />
</center>

<p><br /> The process <img center="" src="http://latex.codecogs.com/gif.latex? \{ \mathbf{X}_i \} _{i \in \mathbb{Z}} " border="0" /> is <img center="" src="http://latex.codecogs.com/gif.latex? \alpha " border="0" />-mixing <i>if and only if </i> <img center="" src="http://latex.codecogs.com/gif.latex? \lim_{i \rightarrow \infty} \alpha(i) = 0 " border="0" />.</p>

<h5>1.3 Weak Dependence</h5>

<h5>1.4 Physical Dependence</h5>

<h5>1.5 Stochastic Matrix</h5>

<p><strong>Reference</strong>
<br />
<br />
[1] Hafner, C. M. and Herwartz, H. (2009) Testing for linear vector autoregressive dynamics under multivariate generalized autoregressive heteroskedasticity, Statistica Neerlandica, 63: 294-323
<br />
[2] Hamilton, J. (1994), Time Series Analysis, Princeton University Press, Princeton.
<br />
[3] Lütkepohl, H. (2006), New Introduction to Multiple Time Series Analysis, Springer, New York.
<br />
[4] Andersen, T. G. (2009), Handbook of Financial Time Series. Springer.
<br />
[5] Qiu H. (2015), Robust Estimation of Transition Matrices in High Dimensional Heavy-tailed Vector Autoregressive Processes.</p>

<hr />

<!--
<br>
[5] Qiu H. (2014), Robust Portfolio Optimization under High Dimensional
Heavy-tailed Time Series;
-->

<!-- blog VIII -->

<!--
<h2>Mediation Analysis on Animal Models</h2>

Last updated: Aug 3, 2016

<div style="background-color:black; color:white; padding:20px;">
<p>￼
<br>
The cat will mew and dog will have his day.
<br>
<br>
- <i>Hamlet</i>: Act 5, Scene 1
</p>
</div>

<br>
XXX

<hr>

-->

<!-- blog X -->

<h2>The Crisis of Big Science</h2>

<p>Last updated: September 5, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
Only two things are infinite, the universe and human stupidity, and I'm not sure about the former.
<br />
<br />
- Albert Einstein
</div>

<p><br />
<strong>Disclaimer:</strong> I do not know anything about Physics; but the discussion below is interesting and could generate helpful discussion with regards to general Science.</p>

<p><br />
<b>A Discussion over the Proposed Chinese Circular Electron Positron Collider (CEPC) Project</b></p>

<p><br />
Currently, there is a warm discussion (<a href="/files/doc/Chinese_Original.pdf"><font color="blue">Chinese original</font></a>, <a href="/files/doc/Translate_Yang_Yau.pdf"><font color="blue">Google English translation</font></a>) between Nobel laureate Chen-Ning Yang and Fields medalist Shing-Tung Yau regarding building the <a href="https://en.wikipedia.org/wiki/Circular_Electron_Positron_Collider">Circular Electron Positron Collider (CEPC)</a>.</p>

<p><br />
<b>A Discussion over the Cancelled American Superconducting Super Collider (SSC) Project</b></p>

<p><br />
<a href="http://www.nybooks.com/articles/2012/05/10/crisis-big-science/ "><font color="blue">Here</font></a> is an article (2012) titled <i>The Crisis of Big Science</i> by Nobel laureate Steven Weinberg regarding a similar, yet cancelled, project, <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Super Collider (SSC) project</a>.</p>

<hr />

<!-- blog VIII -->

<h2>Multidimensional Scaling</h2>

<p>Last updated: September 5, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
There is, it seems to us,
<br /> 
At best, only a limited value
<br />
In the knowledge derived from experience.
<br />
The knowledge imposes a pattern, and falsifies,
<br />
For the pattern is new in every moment
<br />
And every moment is a new and shocking
<br />

Valuation of all we have been. 
<br />
<br />
- T.S. Eliot, <i>East Coker</i>, <i>The Four Quartets</i>
</div>

<p><br />
The idea of multidimensional scaling (MDS) is not new. I am revisiting it; and thought it would be fun to summarize it.</p>

<p><br /> <strong>MDS in a one sentence</strong>
<br />
<br />
Given a <img center="" src="http://latex.codecogs.com/gif.latex? n \times p " border="0" /> data matrix with <img center="" src="http://latex.codecogs.com/gif.latex? n \times n " border="0" /> distance (similarity or disimilarity) matrix, we aim to find a <img center="" src="http://latex.codecogs.com/gif.latex? n \times k " border="0" /> (where <img center="" src="http://latex.codecogs.com/gif.latex? k " border="0" /> can be 2, 3, etc.) map matrix that preserves nearly the same distance information as the distance matrix.</p>

<p><br /> <strong>MDS in a nutshell</strong></p>

<p><br />
We here focus on the MDS in the <i>classical</i> sense, where the distance on the MDS map is of the same metric as the original distance (similarity) matrix. Alternatively, MDS could be ordinal or non-metric (see references below for more detail).</p>

<p><br />
One role statistics has is to allow data reduction to make convenient and succinct inference and conclusion in face of large quantity of data. An convenient and succinct approach to describe how similar or (dissimilar) two objects are is to define a distance (e.g. Euclidean) between them; when we have more than two objects, we can store these distances in a similar (or dissimilar) matrix. A natural follow-up question is why is an object more similar (or dissimilar) to one object than another? For objects with obvious distance metrics (e.g. cities with certain distance from one another), we can plot the distance on a distance map (e.g. in 2D case we could have the x-axis revealing west-east orientation while the y-axis indicating north-south information). What, however, about human faces, that have few descriptive distances (quantitative features) available? This is when the MDS becomes powerful. It transforms the similar (or dissimilar) matrix into a new feature matrix where each dimension (though possibly indescribable) presents an underlying feature.</p>

<p><br /> <strong>Caveats</strong></p>

<p><br />
The term “multi” in MDS indicates that the feature dimension could be more than two or three (though it would be hard to plot when the dimension is greater than 3). The feature could be ambiguous. It allows us to choose how many underlying features we want; and allows us to choose a small numbwer of features that represent the distances well.</p>

<p><br /> 
Formally, let <img center="" src="http://latex.codecogs.com/gif.latex? X " border="0" /> of <img center="" src="http://latex.codecogs.com/gif.latex? n \times p " border="0" /> be the input data with <img center="" src="http://latex.codecogs.com/gif.latex? n " border="0" /> subject and <img center="" src="http://latex.codecogs.com/gif.latex? p  " border="0" /> variables; then one can compute a similarity (or disimilarity) matrix <img center="" src="http://latex.codecogs.com/gif.latex? \Delta = \{ \delta_{ij} \} {1 \leq i, j \leq n} " border="0" />; Finally, the MDS matrix of <img center="" src="http://latex.codecogs.com/gif.latex? D = \{ d_{ik} \} {1 \leq i \leq n, 1 \leq k \leq K} " border="0" /> such that
<img center="" src="http://latex.codecogs.com/gif.latex? \parallel d_i - d_j \parallel \approximate \delta_{ij} " border="0" />, for <img center="" src="http://latex.codecogs.com/gif.latex? 1 \leq i, j \leq I  " border="0" />. Practically, we find</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\hat{d}_1, \ldot, \hat{d}_I = \arg\min _{d_1, \ldot, d_I} \bigg (
\parallel d_i - d_j
\parallel  
- \delta_{ij}
\bigg)^2 
" border="0" />.
</center>

<p><br /> <strong>Goodness of fit</strong></p>

<p><br />
We use the <i>stress</i> to measure the goodness of fit</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
S:= \sqrt{
    \frac{\sum_{i&lt;j} (d_{ij} - \delta_{ij})^2}
    {\sum_{i&lt;j}d_{ij}^2}
}
" border="0" />,
</center>
<p><br />
where, if <img center="" src="http://latex.codecogs.com/gif.latex? S " border="0" /> is close to 0 indicates values of MDS (<img center="" src="http://latex.codecogs.com/gif.latex? \delta_{ij} " border="0" />) are fitting well to the original distances (<img center="" src="http://latex.codecogs.com/gif.latex? d_{ij} " border="0" />).</p>

<p><br />
References:
<br />
<br />
[0] <font color="blue">Theory</font>: Jan de Leeuw and Willem Heiser (1982) <a href="/files/doc/MDS_Tech.pdf">Theory of Multidimensional Scaling </a>.
<br />
[1] <font color="blue">Review</font>: Kruskal, J.B. and M. Wish. 1978. <a href="/files/doc/MDS_Theory.pdf">A Review of Multidimensional Scaling (MDS)
and its Utility in Various Psychological Domains</a>.
<br />
[2] <font color="blue">Introduction</font>: Florian Wickelmaier. 2003. <a href="/files/doc/MDS_Intro.pdf">An Introduction to MDS</a>.
<br />
[3] <font color="blue">Application (a)</font>: Moore, Rod 1990. “Ethnographic assessment of pain coping perceptions.” Psychosomatic Medicine 52:171-181.
<br />
[4] <font color="blue">Application (b)</font>: Blank &amp; Mattes “Sugar and Spice: Similarities and Sensory Attributes” Nursing Research 39(5):290-293.
<br />
[5] <font color="blue">Application (c)</font>: Wexler &amp; Romney. 1972. “Individual Variations in cognitive structures.” in Romney, Shepard &amp; Nerlove eds. Multidimensional Scaling: Theory and Applications in the behavioral sciences, Vol II. Seminar Press.
<br />
[6] <font color="blue">Codes</font>: <a href="http://www.statmethods.net/advstats/mds.html">Quick R</a>.</p>
<hr />

<!-- blog VIII -->
<h2>Imaging Process Techniques in Neuroimaging </h2>

<p>Last updated: August 28, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
If I paint a wild horse, you might not see the horse; but surely you will see the wildness.
<br />
<br />
- Pablo Picasso
</div>

<p><br />
<b>Neural Painting</b></p>

<p><br />
Many of you have used software (e.g. <a href="https://www.instagram.com/?hl=en">Instagram</a>) to adjust or enhance your photoes, and a variety of <a href="https://itunes.apple.com/us/app/autopainter-3/id526292251?mt=8">apps</a> that converts photos into ones that resmeble different art styles such as watercolor and oil, or bear artistical styles such as impressionist paintings); some of you may even heard of neural painting that uses deep learning algorithms to convert any image to a painting that bears a particular painter’s artistic style (see an illustration below), based on <a href="http://arxiv.org/pdf/1508.06576v1.pdf">(Gatys et al, 2015)</a>. There are yet released codes from the paper; we can, however, following the steps on <a href="http://www.makeuseof.com/tag/create-neural-paintings-deepstyle-ubuntu/"> this site</a> (by Andre Infante) to creat such images ourselves; or by sending a source image and style image to <a href="https://twitter.com/DeepForger"> the Deep Forger bot</a> to get an transformed image.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Eiffel.jpg" alt="HTML5 Icon" style="width:750px;" />
        <br />
        
    </a>
</div>
</center>
<p>From left to right are: source image (Eiffel Tower), image of desired artistic style (<i>Starry Night Over the Rhone</i> (aka the other Starry Night) by van Gogh, 1888, oil on canvas), and the output image. (Image credit: <a href="http://www.makeuseof.com/tag/create-neural-paintings-deepstyle-ubuntu/">Andre Infante</a>)</p>

<p><br />
<b>Imaging Process</b></p>

<p><br />
While I do not have much experience in this, I am extremely interested in exploring potentials of it, and have gathered some helpful resource (please refer to the <i>further reading</i> section below) that I would like to share with readers interested in this.</p>

<p><br />
In general, imaging process can be summarized in to the folowing procedures: (1) represent images in image formats (we could think of this as storing image as a cluster of pixels each of which has an intensity); (2) apply image filters (e.g. such as  <a href="http://pippin.gimp.org/image_processing/chap_point.html">point operations</a>, <a href="http://pippin.gimp.org/image_processing/chap_area.html">area operations</a>, and <a href="http://pippin.gimp.org/image_processing/chapter-automaticadjustments.html">automatic color adjustments</a>) (we could think of this as using a variety of transformations to adjust orientation, contrast, brightness, etc); (3) other cosmatic procedures (such as denoise and “dark frame” subtraction, namely to fix bad pixels), and (4) conduct <a href="https://en.wikipedia.org/wiki/Image_analysis">image analysis</a> (such as object recognition, segmentation, motion detection, and video tracking).</p>

<p><br />
Here, let us consider an example in 2D to delineate a simple case.</p>

<p><br /> First, let us script an image from <a href="http://www.estherhonig.com/">Esther Honig</a>, a journalist who did a famous <a href="https://www.buzzfeed.com/ashleyperez/global-beauty-standards?utm_term=.uaoA6LR7kE#.gnNa7BY415">study</a> to present how standards of beauty differ across various cultures. <a href="https://img.buzzfeed.com/buzzfeed-static/static/2014-06/25/13/enhanced/webdr07/original-27318-1403716130-3.jpg?no-auto">This</a> is the image we consider here. Second, we add <img center="" src="http://latex.codecogs.com/gif.latex? n \times m " border="0" /> <img center="" src="http://latex.codecogs.com/gif.latex? N(5,2) " border="0" /> noise to pixels (see image in the left below). Finally, we apply wavelet transform to obtain the process image (see image in the right below).</p>

<p><br />
<a href="/files/doc/Face.R"><strong><font color="blue">Here</font></strong></a> is the R code.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Fig_1.jpeg" alt="HTML5 Icon" style="width:300px;" />
    </a>
    <img src="/images/Fig_2.jpeg" alt="HTML5 Icon" style="width:300px;" />
    <figcaption>Fig 1. Left: Noisy Image; Right: Processed image</figcaption>
</div>
</center>

<p><br /></p>

<p><br />
<b>Further Reading</b></p>

<p><br />
Readers interested in the nitty-gritties could refer to resouces below.</p>

<p><br />
[1] <a href="http://pippin.gimp.org/image_processing/">An Introduction to Pixel Molding (Øyvind Kolås) </a>. The notes are written in accordance with the <i>Gluas</i> app written in <i>Lua</i> scripting language; codes, however, are provided so they can be easily modified to cope with <i>R</i>, <i>Matlab</i>, etc. 
<br /> 
[2]<a href="https://archive.org/details/Lectures_on_Image_Processing ">Lectures on Image Processing (Alan Peters, 2016) </a>.
<br />
[3] <a href="http://www.disi.unige.it/person/RovettaS/rad/image-processing-wikipedia-book.pdf">Image Process</a>.
<br />
[4] <a href="http://www.math.ucla.edu/~lvese/155.1.09w/PCMI_USS_2010/Lectures.pdf">An Introduction to Mathematical Image Processing (Luminita Vese, 2010) </a>.
<br /> 
[5] <a href="http://www.dfstudios.co.uk/articles/programming/image-programming-algorithms/">Image Programming Algorithms (Francis Loch) </a>.
<br /> 
[6] <a href="http://www.ipol.im/">Journal of Image Processing Online </a>.</p>

<hr />

<!-- blog VII -->

<h2>On Intuition: A <i>Bayesian</i> View </h2>

<p>Last updated: August 18, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
<p>￼
<br />
When to the sessions of large data thought,
<br />
I summon up remembrance of things past, 
<br />
I sigh the lack of many priors I sought, 
<br />
And with old prior new experiment my dear posterior's based.
<br />
<br />
- Adapted from a part of Shakespeare's <i>Sonnet XXX</i>
</p>
</div>

<center>

<br />
<b> To</b>
<br />
<b> THOMAS BAYES</b>

</center>

<hr />

<p><b>W</b>E propose that Professors Mikhail Filippov, Varun Prasad and Semir Zeki’s definition of intuition could be mathematically formulated in a Bayesian framework.</p>

<p><br />
<span style="background-color: lightgrey"> <i> An intuition is an unconscious logical brain process with an outcome or conclusion in the form of a  statement or proposition. But whether the outcome of the intuitive process is “right” or “wrong”, or “correct” or “incorrect”, can only be determined by a conscious logical process.</i></span></p>

<p><br />
First, for simplicity, define an event as <img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" />. Here, <img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" /> is a random variable, a random quantity whose value is subject to variations due to chance. For example, looking into the mirror, you think your height (<img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" />) is 72 inches. However, your visual judegement may not always be correct, or that the mirror may not be perfect. Hence, we could put a probability measure <img center="" src="http://latex.codecogs.com/gif.latex? Pr " border="0" /> on <img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" />. If you strongly believe in your judegement, then the probability density <img center="" src="http://latex.codecogs.com/gif.latex? Pr(\theta) " border="0" /> is rather spiky; for example, it covers the height from 71-73. On the other hand, we may have less confidence when a visually-impaired person claims that he finds himself 72 inches tall. In that case, the probability density is rather flat; for example, it covers the height from 61-83. We call <img center="" src="http://latex.codecogs.com/gif.latex? Pr(\theta) " border="0" /> the <b>prior</b>. Another wonderful example of <img center="" src="http://latex.codecogs.com/gif.latex? \theta  " border="0" /> is the location of where a tennis ball lands in a match ( <a href="http://www.nature.com/nature/journal/v427/n6971/abs/nature02169.html">Körding and Wolpert, 2003</a>).</p>

<p><br />
Next, we define the data observed from experiments as <img center="" src="http://latex.codecogs.com/gif.latex? D  " border="0" />. For example, the measured height. Measured heights have errors, too. Furthermore, the measurement error for a child (<img center="" src="http://latex.codecogs.com/gif.latex? \theta = 50 " border="0" />) is in general smaller than it for a basketball player (e.g. Dwight Howard at <img center="" src="http://latex.codecogs.com/gif.latex? \theta = 83 " border="0" />). Therefore, at (conditioning on) every <img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" />, we define the <b>likelihood measure<b> as <img center="" src="http://latex.codecogs.com/gif.latex? Pr (D \vert \theta) " border="0" />.</b></b></p>

<p><br />
Finally, we define the <b>intuition of an event given experimental data </b> (<img center="" src="http://latex.codecogs.com/gif.latex? D " border="0" /> ) as
<img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{I}(\theta \vert D) " border="0" />.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Bayesian.png" alt="HTML5 Icon" style="width:200px;" />
    </a>
</div>
</center>

<p><br />
By Bayes rule, we have:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\mathcal{I}(\theta \vert D) = \frac{ Pr(D \vert \theta) Pr (\theta) } 
{\int_{\Theta} Pr(D \vert \theta) Pr(\theta) }
" border="0" />
</center>

<p><br />
It follows, <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{I}(\theta \vert D) \propto  Pr(D \vert \theta) Pr (\theta) " border="0" />, where <img center="" src="http://latex.codecogs.com/gif.latex? \propto  " border="0" /> stands for <i> proportional to </i>. Let us use the height example to explain this: <img center="" src="http://latex.codecogs.com/gif.latex? \mathcal{I}(\theta = 72 \vert D = d) \propto  Pr(D = d  \vert \theta = 72) Pr (\theta = 72) " border="0" />, which indicates that, our intuition about one’s height being 72 inches, given observed data (<img center="" src="http://latex.codecogs.com/gif.latex? D = d " border="0" />) depends on how well the measurement is, and how strongly our prior information of the height being 72 is. If our previous experience leads us to strongly believe the height is 72 (i.e. <img center="" src="http://latex.codecogs.com/gif.latex? Pr (\theta = 72) " border="0" /> is large), our intuition that the height is 72 would be strong.</p>

<p><br />
The above equation translates as follow: intuition is based upon the data available and the prior experience information. This conclusion echoes with the statement that Professors Mikhail Filippov, Varun Prasad and Semir Zeki made:</p>

<p><br />
<span style="background-color: lightgrey"> <i> We believe, however, that to have an intuition in any area, one must have experience of that area or knowledge of it, to provide a conclusion or statement, whether correct or incorrect. </i></span></p>

<p><br />
Certainly, intuition could change overtime, because our view (prior information) of the world changes. Hence, we could update our Bayesian intuition to one that is “dynamic”, namely:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\mathcal{I}(\theta (t) \vert D) = \frac{ Pr(D \vert \theta (t) ) Pr (\theta (t)) } 
{\int_{\Theta } Pr(D \vert \theta (t)) Pr(\theta (t)) }
" border="0" />
</center>

<p><br />
This may be studied with <a href="https://en.wikipedia.org/wiki/Dynamic_Bayesian_network">Dynamic Bayesian Network (DBN)</a> by Paul Dagum and <a href="https://en.wikipedia.org/wiki/Dynamic_Bayesian_network">Recursive Bayesian estimation (Bayes filter)</a>. I have little knowledge of this, interested readers could refer to corresponding papers.</p>

<p><br />
<b>Other Interpretations</b></p>

<p><br />
Biologically, intuition could be explained by early brain signals preceding decisions (see  <a href="http://www.ncbi.nlm.nih.gov/pubmed/6640273">Benjamin Libet</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/10333013">Haggard and Eimer</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/18408715">Soon et all</a>, and <a href="http://www.pnas.org/content/113/4/1080.full.pdf">Schultze-Kraft</a>).</p>

<p><br />
<b>Further Reading</b></p>

<p><br />
The thought-provoking post on <i> intuition</i>, and other posts regarding the implication of mathematical beauty on asynchronous brain operations, could be found on Professor Semir Zeki’s <a href="http://profzeki.blogspot.co.uk/2016/07/unconscious-intuition-and-its-conscious.html "><strong><font color="blue">blog</font></strong></a>.</p>

<p><br />
Professor Zeki and I would like to encourage discussion and comments. One question I would like to hear our readers’ opinion is: in the above post, I interpret <i>intuition</i> as the <i>posterior</i> that is based upon data and <i>prior information</i> (the latter of which is based upon previous training or experience). However, one could argue that <i>intuition</i> is indeed the <i>prior</i>; and with data, we update and form our <i>belief</i> (the <i>posterior</i>).</p>

<p><br /> 
Further interested readers on these topics could refer to <a href="https://en.wikipedia.org/wiki/Semir_Zeki">Professor Semir Zeki</a>’s books: <a href="http://www.goodreads.com/book/show/1120066.A_Vision_of_the_Brain ">A Vision of the Brain</a>, <a href="https://www.amazon.com/Inner-Vision-Exploration-Art-Brain/dp/0198505191 ">Inner Vision: an exploration of art and the brain</a>, <a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-1405185589.html ">Splendors and Miseries of the Brain</a>, and <a href="https://www.amazon.fr/Balthus-Qu%C3%AAte-lessentiel-Entretiens-S%C3%A9mir/dp/2251440453 ">Balthus ou la quête de l’essentiel</a>, and <a href="http://www.ibs.it/code/9788842093909/lumer-ludovica/bella-bestia:-arte.html ">La bella e la bestia: arte e neuroscienze</a>.</p>

<hr />

<h2>Time Series Analysis in Neuroscience</h2>

<p>Last updated: August 10, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
<p>￼
<br />
If you can look into the seeds of time

<br />
And say which grain will grow and which will not,

<br />
Speak, then, to me, who neither beg nor fear

<br />
Your favors nor your hate.
<br />
<br />
- <i>Macbeth</i> act 1, sc. 3
</p>
</div>

<p><br />
I have spent the past two weeks on the road and air, with intermittent internet access. While having not had the opportunity to keep up what is happening around the world, I had the fortune to re-read Professor <a href="http://www.stat.columbia.edu/~rdavis/">Richard Davis</a>’s wonderful book on <a href="http://www.shsu.edu/sms049/Introduction%20Time%20Series%20and%20Forecasting_Brockwell&amp;Davis.pdf">time series and forecasting</a> on the go. While the book is quite long (400+ pages), I have started to summarize and organize a few (subjective) key elements from the book for future reference. If you are starting to learn time series, I <i>personally</i> think the note might give you a succinct summary of the models used. You can find them <a href="/files/doc/TS.pdf"><strong><font color="blue">here</font></strong></a>. (I will update it regularly). Certainly, the more times I read a book, the more unknowns I found. If you have any recommendation or critism regarding the note, or want the latex file so you can edit it yourself, <a href="mailto:olivery.chen@yahoo.com?Subject=fMRI%20code" target="_top">please let me know</a>.</p>

<p><br /> 
The reason I started to re-read the book was (besides having no internet on the go) that time series analysis is very useful in studying brain data on the time and spectral domain. <a href="http://hombao.ics.uci.edu/Day1-Overview.pdf ">Here</a> is an overview by Professor Hernando Ombao; and Professor Tohru Ozaki has a book called <a href="https://www.crcpress.com/Time-Series-Modeling-of-Neuroscience-Data/Ozaki/p/book/9781420094602">Time series modeling of neuroscience data</a>.</p>

<p><br />
My friend Huitong has written two very beautiful papers (see [6] and [7] below) on high dimensional heavy-tailed time series (which I have little knowledge of, but we had some discussion upon this topic and the potential of extending them in studying “causality” between different brain regions). I have the papers and some interesting references listed below.</p>

<p><br />
[1] Granger, C. W. J. (1969), Investigating causal relations by econometric models and cross-spectral methods, Econometrica, 37: 424-438.</p>

<p><br />
[2] Hafner, C. M. and Herwartz, H. (2009) Testing for linear vector autoregressive dynamics under multivariate generalized autoregressive heteroskedasticity, Statistica Neerlandica, 63: 294-323</p>

<p><br />
[3] Hamilton, J. (1994), Time Series Analysis, Princeton University Press, Princeton.</p>

<p><br />
[4] Lütkepohl, H. (2006), New Introduction to Multiple Time Series Analysis, Springer, New York.</p>

<p><br />
[5] Andersen, T. G. (2009), Handbook of Financial Time Series. Springer.</p>

<p><br />
[6] Qiu H. (2014), Robust Portfolio Optimization under High Dimensional
Heavy-tailed Time Series;</p>

<p><br />
[7] Qiu H. (2015), Robust Estimation of High Dimensional Heavy-tailed Vector Autoregressive Processes.</p>

<hr />

<!-- blog VII -->
<h2>From Network Strength to <i>Effective</i> Network Strength</h2>

<p>Last updated: July 28, 2016</p>

<div style="background-color:black; color:white; padding:20px;">
<p>￼
<br />
You may say I'm a significant voxel, but I'm not the only one. I hope someday you'll join us. And the brain network will live as one.
<br />
<br />
- Adapted from John Lennon's <i>Imagine</i>
</p>
</div>

<p><br />
In this post, we shall propose a framework called the <i>effective</i> network strength, extending the definition of network strength introduced in the wonderful Nature Neuroscience paper by <a href="http://www.nature.com/doifinder/10.1038/nn.4179">Rosenberg et al (2016)</a>. As a natural follow-up, we also define the <i>effective</i> network strength rate.</p>

<p><br />
<b>1. Network strength</b></p>

<p><br /> <a href="http://www.nature.com/doifinder/10.1038/nn.4179">Rosenberg et al (2016)</a> introduced a neuromarker based on intrinsic whole-brain functional connectivity, the degree to which brain activity in distinct neural regions is correlated over time, and showed that functional brain networks strength during a sustained attention task predicted individual differences in performance.</p>

<p><br /> To characterize participant’s degree of connectivity, <a href="http://www.nature.com/doifinder/10.1038/nn.4179">Rosenberg et al (2016)</a> defined <i>network strength</i>, a single summary statistic, which is equivalent to a weighted degree measure for each network. Formally, let us define <img center="" src="http://latex.codecogs.com/gif.latex? S_k " border="0" />, as the <i>network strength</i> for subject <img center="" src="http://latex.codecogs.com/gif.latex? k " border="0" />. Then</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
S_k = \sum_{i,j} \rho_{ij}^{(k)} I_{ijk},
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex?  \rho_{ij}^{(k)} " border="0" /> is the <img center="" src="http://latex.codecogs.com/gif.latex? \{i,j\}^{\text{th}} " border="0" /> entry of the connectivity matrix (here the connectivity matrix is computed by taking the node-wise correlation between node-specific time series); and <img center="" src="http://latex.codecogs.com/gif.latex? I_{ijk} = 1 " border="0" /> if <img center="" src="http://latex.codecogs.com/gif.latex?  \rho_{ij}^{(k)} " border="0" /> follows a specific thresholding rule (e.g. <img center="" src="http://latex.codecogs.com/gif.latex? I_{ijk} = 1  " border="0" /> if <img center="" src="http://latex.codecogs.com/gif.latex?  \rho_{ij}^{(k)} \geq 0.8 " border="0" />), and 0 otherwise.</p>

<p><br />
<b>2. <i> Effective</i> network strength</b></p>

<p><br /> However, a hyperactive subject’s brain could be extremely active during both the resting state and the task state; hence the large correlaton coefficients between nodes that are extremely active during both resting and task states could overshadow the functional changes of other edges. For example, if for a subject there are 100 nodes that are highly correlated during both resting and task states with <img center="" src="http://latex.codecogs.com/gif.latex?  \rho = 0.99 " border="0" /> each (or without significant changes, say from <img center="" src="http://latex.codecogs.com/gif.latex?  \rho = 0.98 " border="0" /> to <img center="" src="http://latex.codecogs.com/gif.latex?  \rho = 0.99 " border="0" />), the change of other edges from 0.001 to 0.1 (despite statistically significant and plausiblly neurobiologically meaningful) would likely to be ignored if we are interested in the node-wise (thresholding) sum (as in <a href="http://www.nature.com/doifinder/10.1038/nn.4179">Rosenberg et al (2016)</a>). Therefore, we propose the definition of <i>effective</i> network strength as follows:</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
S_k^{eff} = E(S_k \vert X_k = 1) - E (S_k \vert X_k=0),
" border="0" />
</center>
<p><br /> where <img center="" src="http://latex.codecogs.com/gif.latex? X_k = 1 " border="0" /> refer to the task state, and <img center="" src="http://latex.codecogs.com/gif.latex? S_k = 0 " border="0" /> refer to the resting state.</p>

<p><br />
<i>Effective</i> network strength describes the average change in network strength due to a change in experimental status. It is experimental dependent; and for numerical tasks, it could be written as <img center="" src="http://latex.codecogs.com/gif.latex? X_k = x " border="0" />, for some task level <img center="" src="http://latex.codecogs.com/gif.latex? x " border="0" />.</p>

<p><br />
As you may have realised, the idea of <i>effective</i> network strength was inspired by <i>effective connectivity</i><a href="http://www.fil.ion.ucl.ac.uk/~karl/Functional%20and%20Effective%20Connectivity%20A%20Review.pdf "> (Friston (2011)</a> and <a href="https://www.researchgate.net/publication/239953112_Dynamics_of_activity_and_connectivity_in_physiological_neuronal_networks ">Aertsen and Preißl (1991)</a>). Nonetheless, <i>effective connectivity</i> regards the effect one neuron has on another and is time dependet, whereas <i>effective</i> network strength is time-independent as when taking the connectivity matrix, the time is averaged out.</p>

<p><br />
<b>3. Network strength with multiple inputs </b></p>

<p><br />
What if we have more than one tasks? And what if are interested in <i>effective</i> network strength between male and female, or between different age groups? To address these interesting questions, we define the conditional network strength on different inputs.</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
S (\boldsymbol{x}) = S (X_1 = x_1, X_2 = x_2, \cdots, X_n = x_n)
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? X_i " border="0" />’s define tasks, and <img center="" src="http://latex.codecogs.com/gif.latex? x_i " border="0" /> is its realization.</p>

<p><br /> For example, <img center="" src="http://latex.codecogs.com/gif.latex? S(\text{treatment} = 1, \text{gender} = 1) " border="0" /> defines network strength under a task for male (gender = 1); and 
<img center="" src="http://latex.codecogs.com/gif.latex? \{S_{gender}^{eff} \vert \text{treatment} = 1 \} = E(S \vert \text{gender} = 1, \text{treatment} = 1) - E (S \vert \text{gender} = 0, \text{treatment} = 1), " border="0" /> defines the gender effect on <i>effective</i> network strength conditioning on treatment.</p>

<p><br />
<b>4. <i> Effective</i> network strength rate</b></p>

<p><br />
Once we have defined the <i>effective</i> network strength, it is natural to define the <i> effective</i> network strength rate: the change (note: could be decrease) of network strength per unit treatment increase.</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\nabla = \frac{\Delta S}{\Delta \boldsymbol{x}} = \frac{S(\boldsymbol{x} + \Delta \boldsymbol{x}) - S (\boldsymbol{x})}{\Delta \boldsymbol{x}} 
" border="0" />
</center>
<p><br />
Certainly, when the task is multidimensional <img center="" src="http://latex.codecogs.com/gif.latex? \boldsymbol{X} = \boldsymbol{x} = (x_1, \cdots, x_n) " border="0" />, the <i>effective</i> network strength rate could be specified at every task direction, namely
<img center="" src="http://latex.codecogs.com/gif.latex? \nabla = \bigg( \frac{\partial}{\partial x_1}, \cdots, \frac{\partial}{\partial x_n} \bigg) " border="0" />.</p>

<p><br /> 
<b>5. Network Strength in a <i>Boltzmann</i> Machine Global Energy Sense</b></p>

<p><br />
<span style="background-color: lightgrey"> <i>The energy of the mind is the essence of life. 
<br />
<br />
- Aristotle </i></span></p>

<p><br />
The global energy in a Boltzmann machine, <img center="" src="http://latex.codecogs.com/gif.latex? E " border="0" />, is defined as follows:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
E = - \bigg (
 \sum_{ij} \rho_{ij} s_i s_j + \sum_i \epsilon_i s_i
\bigg )
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? \rho_{ij} " border="0" /> is the connection strength between unit <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> and unit <img center="" src="http://latex.codecogs.com/gif.latex? j  " border="0" /> (comparing with node-wise correlation in network strength), <img center="" src="http://latex.codecogs.com/gif.latex? s_i \in \{0, 1\} " border="0" /> is the state for unit <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> (comparing <img center="" src="http://latex.codecogs.com/gif.latex? s_i s_j " border="0" /> with <img center="" src="http://latex.codecogs.com/gif.latex? I_{ij} " border="0" /> in network strength), and <img center="" src="http://latex.codecogs.com/gif.latex? \epsilon_i " border="0" /> is the bias of unit <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> in the global energy (this is not present in network strength - yet it could because data driven node-wise correlation is likely to have bias).</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Energy_landscape.png" alt="HTML5 Icon" style="width:500px;" />
        <br />
        Energy Landscape of a Boltzmann (Hopfield) Network 
        <br />(Image source: Wikipedia)
    </a>
</div>
</center>

<p><br />
Due to the properties of Boltzmann energy function and its similarity with network strength function, at resting state (and possibly at task state), when the node-wise correlation could be updated, it will be interesting to show that the network strength function (1) is a Lyapunov function, and (2) has Markov property. (1) indicates that the network strength will eventually converge to a state which is a local minimum; and (2) tells us that we could impose probability measure on network strength.</p>

<!-- http://economics.mit.edu/files/32 -->

<hr />

<!-- blog VII -->
<h2>On Brain Fingerprinting: Extensions </h2>

<p>Last updated: July 20, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼The unique fingerprint of every individual defines our unique purpose and mission on earth.</p>

– Lailah Gifty Akita
</div>

<p><br />
In this post, we shall discuss the wonderful <a href="http://www.nature.com/neuro/journal/v18/n11/full/nn.4135.html">brain fingerprinting paper</a> published on <i>Nature Neuroscience</i> by Finn et al, and present a few potential extensions.</p>

<p><br />
<b>1. Recap</b></p>

<p><br />
First, let us briefly describe the dataset and the <i>fingerprinting</i> procedures in <a href="http://www.nature.com/neuro/journal/v18/n11/full/nn.4135.html">Finn et al (2015)</a>. The study has 126 subjects, each subject has 268 nodes, each subject is measured at <img center="" src="http://latex.codecogs.com/gif.latex? T " border="0" /> time points (rigorously we should write <img center="" src="http://latex.codecogs.com/gif.latex? T_i, \forall 1 \leq i \leq 6 " border="0" /> because the time points vary between sessions), and there are six image sessions: two resting sessions (rest 1 [on day 1], rest 2 [on day 2]) and four task sessions: working memory, emotion, motor and language (two on each day). Therefore, the dataset is</p>

<center> <img center="" src="http://latex.codecogs.com/gif.latex?
126 \times \underbrace{268 \times T}_{\text{compute} \hspace{2mm} 268 \times 268 \hspace{2mm} \text{node-wise correlation matrix}} \times 6.
" border="0" />
</center>

<p><br />
For every subject at each image session, we could convert the <img center="" src="http://latex.codecogs.com/gif.latex? 268 \times T " border="0" /> matrix into a <img center="" src="http://latex.codecogs.com/gif.latex? 268 \times 268 " border="0" /> node-wise correlation matrix. Therefore, at each session, we have 126 subject-specific node-wise correlation matrix. Next, we vectorize each node-wise correlation matrix. Finally, consider subject <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> from one image session (say Rest 1). To find a matching subject from another image session (say Rest 2), we take <img center="" src="http://latex.codecogs.com/gif.latex? \bold{v}_i ^{(1)} " border="0" />, the vectorized node-wise correlation matrix for subject <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" />, where the superscript indicates it is from the first image session, to each of vector in the Rest 2. The subject identified is the one who achieves</p>
<center> 
<img center="" src="http://latex.codecogs.com/gif.latex?
\rho_{i j*}^{(1,2)} = \arg\max_{1^* \leq k^* \leq 126^*} \rho_{i k^*}^{(1,2)}.
" border="0" />
</center>

<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? \rho_{i j*}^{(1,2)} = corr(\bold{v}_i^{(1)}, \bold{v}_{j^*}^{(2)}). " border="0" /></p>

<p><br />
Notice, the <img center="" src="http://latex.codecogs.com/gif.latex? * " border="0" /> indicates that subject <img center="" src="http://latex.codecogs.com/gif.latex? 15^* " border="0" /> in Rest 2 may differ from subject 15 in Rest 1.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Fingerprinting.png" alt="HTML5 Icon" style="width:500px;" />
    </a>
</div>
</center>

<p><br />
<b>2. Extensions</b></p>

<p><br />
<b> 2. 1. Brain topology v.s. brain function on identication accuracy </b></p>

<p><br />
The paper claims that identification power came from true differences in functional connectivity rather than anatomic idiosyncrasies. To support the claim, the authors used kernel smoothing on connectivity matrices, and showed that, with larger smoothing kernels (under which the registration advantages for the same brain compared to different brains should be vastly reduced or eliminated), only a slight drop in identification power. One may argue that smoothing does not eliminate differences caused by topology fully. Let us take an extreme example: consider two subjects (S1 and S2) with significant anatomical difference in 100 adjacent nodes, where the brain measurements of S1 for these nodes during two sessions are nonzeros, and those of S2 for these nodes during two sessions are all zeros. In this case, for those 100 nodes, a large <a href="http://www.biostat.jhsph.edu/~ririzarr/Teaching/649/section-06.pdf">smoothing kernel</a> (unless an infinite bandwidth is chosen), will give S1 small but nonzero smoothed brain measurements whereas S2 has all zeros. Therefore, S1 in one image session would still match S1 in another session, and so is S2 - this could potentially argue against the functional connectivity claim.</p>

<p><br />
To better eliminate anatomic idiosyncrasies, we need brains that are particularly similar anatomically. One could start by looking at the HCP twin data, concerning that the brain topology between identical twins is almost the same. Using the HCP twin and non-twin data, we could then ask three questions: is brain fingerprinting (1) due to brain functions alone, (2) due to brain topology, or (3) due to a combination of (1) and (2). Let us call the identication accuracy rate for twins as <img center="" src="http://latex.codecogs.com/gif.latex? T " border="0" /> and it for non-twins as <img center="" src="http://latex.codecogs.com/gif.latex? NT " border="0" />, both of which are in percentage. If <img center="" src="http://latex.codecogs.com/gif.latex? T \sim NT  " border="0" />, then we conclude that brain fingerprinting is not due to topoloty; if <img center="" src="http://latex.codecogs.com/gif.latex? 0 &lt;&lt; T &lt; NT  " border="0" /> (i.e. we still achieve some accuracy using twin data, but not as good as if we use non-twin data) then we conclude that brain fingerprinting is due to a combination of brain function and topology; and if <img center="" src="http://latex.codecogs.com/gif.latex? T \rightarrow 0, NT &gt;&gt; 0 " border="0" /> (i.e. we almost cannot fingerprint twins), then we conclude that brain fingerprinting is due merely to brain topology. It would be interesting to see how much identification accuracy is due to functional connectivity and how much due to anatomic idiosyncrasies, via proposing a <i>Functional/Anatomic Ratio Score</i>, by studying the twin and non-twin data.</p>

<p><br />
<b> 2. 2. “Dynamic” brain fingerprinting </b></p>

<p><br />
The study showed that “<i>longer time courses better preserved individual characteristics in connectivity profiles</i>”. However, it would be interesting in examining if the identification accuracy rate changes across the time of the day. This question is driven by studies we did on physical activity data analysis, where our daily physical activity on average follows a “M” shape. It will be tremendously interesting if the identification accuracy rate across time somewhat matches the physical activity pattern (especially during task sessions) - which would indicate that stronger physical activity could possibly facilitate brain fingerprinting. See below.</p>
<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Fingerprinting_physical_avctivity.png" alt="HTML5 Icon" style="width:400px;" />
    </a>
</div>
</center>

<p><br />
Here, we present the brief procedure. First, divide the total time points in a time <img center="" src="http://latex.codecogs.com/gif.latex? T " border="0" /> into <img center="" src="http://latex.codecogs.com/gif.latex? N " border="0" /> periods, each with <img center="" src="http://latex.codecogs.com/gif.latex? t " border="0" /> time points, i.e. <img center="" src="http://latex.codecogs.com/gif.latex? T = N \times t " border="0" />. For every <img center="" src="http://latex.codecogs.com/gif.latex? t " border="0" /> time points, we repeat the fingerprinting procedure discussed in the paper, and obtain <img center="" src="http://latex.codecogs.com/gif.latex? N " border="0" /> identification accuracy rates, and call them <img center="" src="http://latex.codecogs.com/gif.latex? R_1, \cdots, R_N " border="0" />. Finally, we plot <img center="" src="http://latex.codecogs.com/gif.latex? R_1, \cdots, R_N " border="0" /> against <img center="" src="http://latex.codecogs.com/gif.latex? N " border="0" /> time points of the day.</p>

<p><br />
<b> 2. 3. Age, gender, etc. effects on identification accuracy rate </b>
<br /> It would be interesting to investigate the age effect on identification accuracy rate. If there is a obvious difference identification accuracy rate between age groups, one may argue that this is due to functional difference related to age. Potentially, there could be six types of age effect trends (see below). Based on the trend, the age effect on identification accuracy rate would gain us neurobiological understanding of the brain functional similarity due to age: for example, the top left image below would indicate that the brain functions are the most stable (similar between two sessions) during one’s adulthood while not so much during childhood (possibly in that kids’ brain signals are super active one day and less so the second day or their state of mind has more variations - possibly not yet functionally matured), nor during ederly population (possibly due to lesions); the image to its right would indicate that age seems to not affect measured brain functions significantly.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Age_effect.png" alt="HTML5 Icon" style="width:500px;" />
    </a>
</div>
</center>

<p><br />
Similarly, one may look at the diffence of identification accuracy rate between male and female.</p>

<p><br />
<b> 2. 4. Neurodegenerative Disease Similarities due to Brain Functions </b> 
<br />
One may be interested in seeing association between differentn neurodegenerative diseases due to functional similarities. For example, one may ask, amongst patients who develope Parkinson’s (PD) , Alzheimer’s (AD), and Huntington’s (HD) diseases, are PD patients brain functions more similar to AD’s, than to HD’s?</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Disease.png" alt="HTML5 Icon" style="width:600px;" />
    </a>
</div>
</center>

<p><br />
Let us take an example to describe the procedure. Consider two task-based imaging sessions: working memory and motor (we choose these two because AD and PD patients’ brain functions may be correlated with respect to these two tasks). Now for subjects under the working memory task group, we could group them according their disease status. For those in the motor group, we could randomize the order of subjects (because our goal is to see how well we match patients in different disease groups). Next, we vectorize each correlation matrix; and calculate correlations between these vectors in two task groups. The results are stored in a <i>disease-specific (dis)similarity matrix<i> due to brain functions.</i></i></p>

<p><br />
Certaily, the same subjects would likely be accurately matched; nonetheless, it would be interesting to see if the subjects in the same disease group are matched. The grouping is present in a disease-specific (dis)similarity matrix.</p>

<p><br />
<b> 2. 5. Brain-Genome Fingerprinting </b>
Whilst genomic information may assist identify subjects alone (I have little knowledge about whether there are exisiting works on this), to match subjects using brain functions along with genomic information during two sessions gains us little because genes for the same subject do not vary much during these sessions; adding brain measurements into gene information would even likely to reduce identification accuracy rate. Nevertheless, it would be interesting to see if we could match one’s brain functions with gene sequence, and <i>vice versa</i>. However, one may argue, if the matching is accurate, we are actually matching gene sequence with brain <i>structure</i>, rather than with brain <i>function</i>. I am not able to adress this, even with the twin data in (2.1), because identical twins are likely to have similar brain structures, and have the same DNA (assuming SNPs are ignorable).</p>

<p><br />
<b> 2. 6. Fingerprinting Defining Matrix</b></p>

<p><br />
Consider <img center="" src="http://latex.codecogs.com/gif.latex? Y_1 " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? Y_2 " border="0" />, each of which is <img center="" src="http://latex.codecogs.com/gif.latex? n \times v " border="0" />, where <img center="" src="http://latex.codecogs.com/gif.latex? n " border="0" /> is the number of subject and <img center="" src="http://latex.codecogs.com/gif.latex? v " border="0" /> is the number of vectorized nodes, as data from two sessions. In particular, for example, the first row of <img center="" src="http://latex.codecogs.com/gif.latex? Y_1 " border="0" /> is the node-wise correlation matrix for subject 1 in session 1 vectorized.</p>

<p><br />
We then define a <img center="" src="http://latex.codecogs.com/gif.latex? n \times n " border="0" /> (where <img center="" src="http://latex.codecogs.com/gif.latex? n " border="0" /> is the number of subjects) <i>Fingerprinting Defining Matrix</i>, where if (consider row-wise) the <img center="" src="http://latex.codecogs.com/gif.latex? (i,j)^{\text{th}} " border="0" /> entry is the largest among all entries in row <img center="" src="http://latex.codecogs.com/gif.latex? j " border="0" />, we say subject <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> in session 1 matches subject <img center="" src="http://latex.codecogs.com/gif.latex? j " border="0" /> in session 2.</p>

<p><br />
The <i>Fingerprinting Defining Matrix</i> <img center="" src="http://latex.codecogs.com/gif.latex? M " border="0" /> of dimension <img center="" src="http://latex.codecogs.com/gif.latex? n \times n " border="0" /> satisfies:</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
M = \arg\min_{ X } \{ \parallel X \parallel _{\mathcal{F}}: Y_1^T X Y_2  = V_1^2 V_2^2 \},
" border="0" />
</center>

<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? V_1 " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? V_2 " border="0" /> are scaling matrices of <img center="" src="http://latex.codecogs.com/gif.latex? Y_1 " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? Y_2 " border="0" />, respectively.</p>

<p><br /> In other words, there are a lot of matching matrices that allows <img center="" src="http://latex.codecogs.com/gif.latex? Y_1^T X Y_2  = V_1^2 V_2^2 " border="0" /> (i.e. obtain the “product variance” of data from both sessions); but <img center="" src="http://latex.codecogs.com/gif.latex? M " border="0" /> is the matching matrix with the smallest matrix norm to achieve so.</p>

<p><br />
Indeed, the correlation matrix <img center="" src="http://latex.codecogs.com/gif.latex? P = Y_1^T Y_2 " border="0" /> achieves that <img center="" src="http://latex.codecogs.com/gif.latex? Y_1^T P Y_2  = V_1^2 V_2^2 " border="0" /> because <img center="" src="http://latex.codecogs.com/gif.latex? Y_1^T P Y_2 = D_1^T V_1 S_1^T (S_1 V_1 D_1 D_2^T V_2 S_2^T) S_2 V_2 D_2 = V_1^2 V_2^2 " border="0" />. However, <b>I do not have a proof</b> that the correlation matrix is the matching matrix that has the smallest matrix norm to achieve <img center="" src="http://latex.codecogs.com/gif.latex? Y_1^T X Y_2  = V_1^2 V_2^2 " border="0" />. It would be interesting if someone could prove this (or disprove this). If the former, then we will have a mathematical interpretation for the correlation matrix to be a <i>fingerprinting matching matrix</i> that matches the data from two sessions to abtain the “product variance” from the two data sets.</p>

<p><br />
<b> 2. 7. Connecting Brain Fingerprinting with Encoding models, RSA, and Decoding Models</b></p>

<p><br />
The connectivity matrix approach used in <a href="http://www.nature.com/neuro/journal/v18/n11/full/nn.4135.html">Finn et al (2015)</a> is in essence identical to it used in <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605405/pdf/fnsys-02-004.pdf ">RSA (Kriegeskorte et al, 2008)</a>. A few extensions could be made linking these approaches (I will write another post on this on a later date). Here, I would like to discuss the <i>behavioral prediction</i> discussed in the paper and potential extensions.</p>

<p><br /> The paper uses <i>feature network strength</i> to predict <i>gFscore (fluid intelligence)</i> score. For subject <img center="" src="http://latex.codecogs.com/gif.latex? k " border="0" /></p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
gF_k (X_k) = \beta_0 +  \beta_1 X_k  + \epsilon_k,
" border="0" />
</center>

<p><br />
where
<img center="" src="http://latex.codecogs.com/gif.latex? X_k = \sum_{i,j} \stackrel{(k)}{\rho^{(+)}_{ij}} " border="0" /> is the positive <i>feature network strength</i> for subject <img center="" src="http://latex.codecogs.com/gif.latex? k " border="0" />, which sums up all significant (by thresholding) postive correlation <img center="" src="http://latex.codecogs.com/gif.latex? \rho_{ij} " border="0" />’s. The model for negative <i>feature network strength</i> could be Similarly defined.</p>

<p><br />
The prediction is well done. However, since the correlation between predicted and observed gF scores was <img center="" src="http://latex.codecogs.com/gif.latex? r = 0.50 (p&lt; 10^{-9}) " border="0" /> for the positive-feature model and <img center="" src="http://latex.codecogs.com/gif.latex? r = 0.26 (P = 0.005) " border="0" />, it would be interesting to see if there are things we could improve upon.</p>

<p><br />
First, we could check if a subregion of connectivity matrix (e.g. only take the part of the connectivity matrix whose nodes correspond to Broca’s and Wernicke’s areas) under specific tasks (e.g. language) would predict gF better. Second, since the authors used simple linear regression to train the data, we could investigate if there is a model that better fits the training data (and hence have a better leave-one-out prediction). For example, a non-linear model</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
gF_k(X_k) = f(X_k) + \epsilon_k,
" border="0" />
</center>

<p><br /> 
where <img center="" src="http://latex.codecogs.com/gif.latex? f " border="0" /> is some non-linear mapping. Or a semiparametric model</p>

<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
gF_k(X_k) = f(X_k, \theta, \gamma) + \epsilon_k,
" border="0" />
</center>

<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? \theta " border="0" /> is some finite-dimensional parameter of neurobiological interest, and <img center="" src="http://latex.codecogs.com/gif.latex? \gamma " border="0" /> is a nuisance parameter (such as the BOLD signal variance in each node).</p>

<p><br />
<b>3. Conclusion</b></p>

<p><br /> 
In summary, <a href="http://www.nature.com/neuro/journal/v18/n11/full/nn.4135.html">Finn et al (2015)</a> is a tremendously interesting paper that demonstrated existing subject-specifi functions in the brain. I eagerly look forward to more exciting follow-up works from the group.</p>

<hr />

<!-- blog VI -->
<h2>On Task-based <i>Age</i> and <i>Gender</i> Effects on <i>Spatial</i> Brain Representations: with Applications to the Human Connectome Project </h2>

<p>Last updated: July 16, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼Biology gives you a brain. Life turns it into a mind.</p>

– Jeffrey Eugenides

</div>

<p><br /> 
I had the idea of this post after an inspirational conversation with Professor <a href="http://www.med.upenn.edu/apps/faculty/index.php/g293/p3226">Ruben Gur</a>, who, together with his wife, Professor <a href="http://www.med.upenn.edu/apps/faculty/index.php/g275/p11144"> Raquel Gur</a>, are world-renowned experts in neuropsychology, and have done a tremendous amount of work in gender and age differences in the brain.</p>

<p><br />
Here, I would like to propose a functional mixed effect model to investigate how gender and age effects on encoded (representational) <i> spatial</i> brain signals under (i.e. conditioning on) different tasks. This framework can be implemented to study the <a href="https://wiki.humanconnectome.org/display/PublicData/HCP+Data+Dictionary+Public-+500+Subject+Release">500-subject datasets</a> from the <a href="https://www.humanconnectome.org/">Human Connectome Project</a>, with a goal to understand age and gender effects on the following main categories: alertness, cognition, emotion, motor function, personality, sensory, substance use, etc. Each main category could be further divided into subcategories: e.g. one may be interested in studying age and gender effects on emotion, in particular, psychological well-being.</p>

<p><br />
We consider a marginal model for the brain activity data. Specifically, for subject <img center="" src="http://latex.codecogs.com/gif.latex? i " border="0" /> at visit <img center="" src="http://latex.codecogs.com/gif.latex? j " border="0" />, consider:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
y_{ij}(\nu_k) \vert x_{ij}, z_i = \alpha(\nu_k, x_{ij}) + z_i \beta (\nu_k, x_{ij}) + \epsilon_{ij} (\nu_k),
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? \nu_k \in \mathcal{V} " border="0" /> indicates the <img center="" src="http://latex.codecogs.com/gif.latex? k^{\text{th}} " border="0" /> voxel (for simplicty, we could vecterize voxels in a 3-D brain to a long vector), <img center="" src="http://latex.codecogs.com/gif.latex? y_{ij}(\nu_k) " border="0" /> is the voxle-specific intensity, <img center="" src="http://latex.codecogs.com/gif.latex? x_{ij} " border="0" /> is the age, <img center="" src="http://latex.codecogs.com/gif.latex? z_i " border="0" /> is the gender, and the error follows a working model</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
\epsilon_{ij} (\nu_k) = b_i (\nu_k) + w_{ij} (\nu_k) + \epsilon_{ijk},
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? b_i (\nu_k) " border="0" /> models the subject-specific mean function of brain activity, <img center="" src="http://latex.codecogs.com/gif.latex? w_{ij} (\nu_k) " border="0" /> models the deviation of the <img center="" src="http://latex.codecogs.com/gif.latex? j^{\text{th}} " border="0" /> visit from the subject-specific mean function, and <img center="" src="http://latex.codecogs.com/gif.latex? \epsilon_{ijk} \sim N(0, \sigma_\epsilon^2). " border="0" /> Furthermore, we model <img center="" src="http://latex.codecogs.com/gif.latex? b_i (\nu) " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? w_{ij} (\nu) " border="0" /> by two zero mean Gaussian processes with <i> spatial</i> covariance
functions <img center="" src="http://latex.codecogs.com/gif.latex? \Sigma^b(\nu,v) " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? \Sigma^w(\nu,v) " border="0" />, respectively. Finally, we assume that <img center="" src="http://latex.codecogs.com/gif.latex? b_i (\nu) " border="0" />, <img center="" src="http://latex.codecogs.com/gif.latex? w_{ij} (\nu) " border="0" />, and <img center="" src="http://latex.codecogs.com/gif.latex? \epsilon_{ijk} " border="0" />, are mutually independent.</p>

<p><br />
To interpret the model, here <img center="" src="http://latex.codecogs.com/gif.latex?  \alpha(\nu, x) " border="0" /> is the brain activity mean surface, specifically, <img center="" src="http://latex.codecogs.com/gif.latex?  \alpha(\nu_k, x_{ij}) " border="0" />  gives the mean brain activity for voxel <img center="" src="http://latex.codecogs.com/gif.latex? \nu_k " border="0" /> and age <img center="" src="http://latex.codecogs.com/gif.latex? x_{ij} " border="0" />; <img center="" src="http://latex.codecogs.com/gif.latex?  \beta(\nu, x) " border="0" /> is the brain activity slope surface, specifically, <img center="" src="http://latex.codecogs.com/gif.latex?  \beta(\nu_k, x_{ij}) " border="0" />  indicates the brain activity difference due to gender for voxel <img center="" src="http://latex.codecogs.com/gif.latex? \nu_k " border="0" /> and age <img center="" src="http://latex.codecogs.com/gif.latex? x_{ij} " border="0" />.</p>

<p><br /> It would be relatively straightforward to implement computational wise if one’s research focus is on ROIs (in other words, the number of voxels is reasonably small). When the number of voxels is large, we may run into computational problems, because we are essentially dealing with a huge surface of <img center="" src="http://latex.codecogs.com/gif.latex? N \times p " border="0" />, where <img center="" src="http://latex.codecogs.com/gif.latex? N " border="0" /> is the number of ages and <img center="" src="http://latex.codecogs.com/gif.latex? p " border="0" /> is the number of voxels. We may then consider dimension reduction or assume that the brain network is sparse. We shall not expatiate on this here; interested readers could consider approaches such as SVD, fPCA, ridge regression, etc.</p>

<p><br />
Readers who are interested in the estimating procedures of the above model could discuss with me <a href="mailto:olivery.chen@yahoo.com?Subject=fMRI%20code" target="_top">via email</a>. If one is interested in learning more about functional data analysis, please refer to the following wonderful resources: <a href="http://www.springer.com/us/book/9780387400808">Ramsay (2006)</a> proivdes a broad overview of functional data analysis methods with applications to curve and image analysis; and <a href="http://www.stat.tamu.edu/~carroll/semiregbook/">Ruppert et al. (2003)</a> overviews functional data analysis in the semiparametric framwork in detail.</p>

<p><br /> 
This framework can be implemented to study age, gender, and age-gender effects on sensory data (audition, olfaction, pain, taste, vision), on substance use (alcohol, tobacco, and drug), psychiatric and life function, motor (endurance, locomotion, dexterity, and strength), emotion (emotion recognition, negative affect, psychological well-being, social relationships, stress and self efficacy), cognition (episodic memory, executive function/cognitive flexibility, executive function/inhibition, fluid intelligence, language/reading decoding, language/vocabulary comprehension, processing speed, self-regulation/impulsivity, spatial orientation, sustained attention, verbal episodic memory, working Memory, and alertness (cognitive status, and sleep). Each area could be developed into a journal article using the above framework.</p>

<hr />

<!-- blog IV -->
<h2>On Generating Artificial Functional Magnetic Resonance Imaging (fMRI) Data (II): Dynamic 3D Visualization</h2>

<p>Last updated: June 7, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼The human brain starts working the moment you are born and never stops until you stand up to speak in public.</p>

– George Jessel

</div>

<p><br /> 
Once we understand the data generation mechanism of fMRI data, and have become familiar with the parameters needed, we can proceed to simulate desired fMRI data. There are many wonderful articles providing examples and codes for simulating fMRI data (see, for example, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjf2c_TzJHNAhWKFj4KHbbYCzIQFggdMAA&amp;url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv044i10%2Fv44i10.pdf&amp;usg=AFQjCNFBBPszyk5wZzmLI7HN_xC8EsrjpA">Welvaert et al</a>). For a list of software for medical image analysis, see <a href="https://cran.r-project.org/web/views/MedicalImaging.html">here</a>.</p>

<p><br /> 
Here I shall focus on visualization of simulated fMRI data, so as to examine the quality of the realizatio of the simulation, such as, if we are to simulate fMRI data for a regional brain lesion, do the simulated fMRI datasets accord with real world scenarios? Additionaly, I am interested in seeing the intensity of signal changes across time. This has real world implications. For example, visualizing <a href="http://www.sciencedirect.com/science/article/pii/S0959438807000396">the brain dynamic functional connectivity</a>; visualizing the growth of tumors; and etc. Let us consider a concrete example. Consider a patient with two brain regions associated with abnormal activities (e.g. the patient has two tumors); and we wish to simulate fMRI data in this scenario. Below, on the left we present dynamic 2-D intensity of simulated data for a slice (a cross-section) of the patient’s brain during 100 scans (with TR = 2); and on the right we present the dynamic 3-D image of threshold activities for the first 20 scans. Notice the two regions with intensive signals.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/tumor.gif" alt="HTML5 Icon" style="width:200px;" />
    </a>
    <img src="/images/Tabelow.gif" alt="HTML5 Icon" style="width:200px;" />
    <img src="/images/3D.gif" alt="HTML5 Icon" style="width:200px;" />
</div>
</center>

<p><br />
Please <a href="mailto:olivery.chen@yahoo.com?Subject=fMRI%20code" target="_top">send me an email</a> if you want the code for generating above dynamic 2D/3D plots.</p>

<p><br />
For generating static 3D plot, there is a terrific article written by <a href="https://journal.r-project.org/archive/2014-1/muschelli-sweeney-crainiceanu.pdf "> Muschelli et al</a>.</p>

<p><br />
For generating static 2D plot, there is a terrific article written by  <a href="/files/doc/Tabelow.pdf">Tabelow et al</a>. The data are <a href="/files/doc/Tabelow_data">here</a>. <a href="https://www.wias-berlin.de/projects/matheon_a3/doc/poster-HBM2011-fmri.pdf">Here</a> is some further reading.</p>

<hr />

<!-- blog III -->

<h2>On Generating Artificial Functional Magnetic Resonance Imaging (fMRI) Data (I): Generating Mechanism</h2>

<p>Last updated: June 5, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>Understanding how the brain works is arguably one of the greatest scientific challenges of our time.</p>

– Alivisatos et al

</div>

<p><br /></p>

<p><br /> 
A useful approach to develop one’s skills in investigating human brain data is to understand incisively the data generation mechanism. At the low level, one may look at the <a href="https://en.wikipedia.org/wiki/Action_potential#Process_in_a_typical_neuron"> biophysical basis of action potential</a>, <a href="http://link.springer.com/referenceworkentry/10.1007/978-1-4614-7320-6_683-1"> spike-timing dependent plasticity</a>, <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142435">neuronal dynamics</a>, etc. I have little knowledge in these areas; but interested readers can refer to <a href="http://www.ndcn.ox.ac.uk/team/rafal-bogacz">Bogacz</a>, <a href="http://learning.eng.cam.ac.uk/Public/Lengyel/WebHome">Lengyl</a>, <a href="https://www.ini.uzh.ch/~jpfister/">Pfister</a>, amongst other great scientists working in these fields. Here, I aim to discuss the data generating mechanism at the voxel level, mainly, fMRI data. I have learned a tremendous amount from two wonderful papers: (1) <a href="http://www.ncbi.nlm.nih.gov/pubmed/24586801">Eloya et al</a>; and (2) <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjf2c_TzJHNAhWKFj4KHbbYCzIQFggdMAA&amp;url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv044i10%2Fv44i10.pdf&amp;usg=AFQjCNFBBPszyk5wZzmLI7HN_xC8EsrjpA">Welvaert et al</a>. The post serves as a self-learning guide, as I selectively walk through a few key steps. <a href="/files/doc/fMRI_glossary.pdf">Here</a> is a useful reference of MRI glossary. I shall write another post in the near future discussing the importance of knowing the <i> exact </i> data generating mechanism on making “causal” claims, etc.
<br /></p>

<h4>Part 1: Model Basics</h4>
<p>First, fMRI data can be decomposed into two parts: (a) signals (experimental design caused activation, or resting state activation); and (b) noises. Namely,</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex?
s(t) = h(t) + \epsilon(t),
" border="0" />
</center>
<p><br />
where <img center="" src="http://latex.codecogs.com/gif.latex? s(t), h(t), " border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? \epsilon(t)" border="0" /> are signal response, activation function, and noise, respectively, at time <img center="" src="http://latex.codecogs.com/gif.latex? t" border="0" />.
<br /></p>

<h4>1.1 Signals</h4>

<p>The activation function <img center="" src="http://latex.codecogs.com/gif.latex?h(t) " border="0" /> is convolved from <img center="" src="http://latex.codecogs.com/gif.latex? h(t) = f(t)*g(t) = \int_{-\infty}^{\infty} f(\tau) g (t-\tau) d\tau" border="0" />, where we can treat <img center="" src="http://latex.codecogs.com/gif.latex? f(t)" border="0" /> and <img center="" src="http://latex.codecogs.com/gif.latex? g(t)" border="0" /> as a stimulas function (dependent upon experiemental design) and a “weight” function (a haemodynamic response
function (HRF)), respectively. Then <img center="" src="http://latex.codecogs.com/gif.latex?h(t) " border="0" /> is, intuitively, a weighted (by <img center="" src="http://latex.codecogs.com/gif.latex?g(t) " border="0" />) average of <img center="" src="http://latex.codecogs.com/gif.latex?f(t) " border="0" /> over the real line. For example:</p>
<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Convolution_of_spiky_function_with_box.gif" alt="W3Schools.com" />
</center>
<p>There are a few choices of HRFs (<img center="" src="http://latex.codecogs.com/gif.latex? g(t)" border="0" />), e.g., Gamma, double-Gamma, and the balloon model. Here, we take the Gamma function as an example. Consider the gamma-variate HRF function:</p>
<center>
<img center="" src="http://latex.codecogs.com/gif.latex? 
g(t) = \frac{1}{k \tau_h (k-1)} \left( \frac{t}{\tau_h} \right)^k \exp{\{- \frac{t}{\tau_h}\}}
" border="0" /> 
</center>
<p>with <img center="" src="http://latex.codecogs.com/gif.latex? k=3" border="0" />  and <img center="" src="http://latex.codecogs.com/gif.latex? \tau_h = 0.242" border="0" />;</p>

<p><br />
Consider a block function <img center="" src="http://latex.codecogs.com/gif.latex?f(t) " border="0" /> (corresponding to a block experimental design; and in the following figure, the black lined blocks), then the convolved activation function <img center="" src="http://latex.codecogs.com/gif.latex?h(t) " border="0" /> using gamma-variate HRF function is shown below in dashed blue:</p>

<p><img src="/images/Figure_1.jpeg" alt="HTML5 Icon" style="width:512px;" />
<!-- --></p>
<h4>1.2 Noises</h4>
<p>There are four types of noises: (1) white noise, (2) colored noise, (3) temporal noise, and (4) spatial noise.</p>

<h5>1.2.1 White Noises</h5>
<ol>
  <li>a. It is a system noise that is part of the fMRI data.</li>
  <li>b. It could be <i>Rician</i> distributed (for fMRI data with low signal-to-noise ratio, SNR); or <i>Gaussian</i> distributed (higher SNR, &gt; 10).</li>
</ol>

<h5>1.2.2 Colored Noises</h5>
<ol>
  <li>a. It depends upon the signal, the timing or the location</li>
  <li>b. For signal-dependent colored noises, it could be 
(a) low-frequency drift (due to slow fuctuations in the scanner hardware; the drift is modeled as a basis of discrete cosine functions);
(b) physiological noise (models the variability in the signal that is caused by cardiac and respiratory artefacts; the noise is modeled as sine and cosine functions); and
(c) task-related noise (accounts for spontaneous neural activity due to the experimental
task; modeled by adding random noise where and when activation is present; and it can be interpreted as residual noise from head motion that is not removed in the pre-processing stage).</li>
</ol>

<h5>1.2.3 Temporal Noises</h5>
<ol>
  <li>a. Due to the fact that fMRI data are repeated measurements;</li>
  <li>b. It could be modeled as an <img center="" src="http://latex.codecogs.com/gif.latex?AR(p) " border="0" /> model:
<img center="" src="http://latex.codecogs.com/gif.latex? \epsilon(t) = \sum_{i=1}^p \rho_i \epsilon_{t-i} + \eta_i, " border="0" />
where <img center="" src="http://latex.codecogs.com/gif.latex? \eta_i \sim N (0, \sigma^2) " border="0" />.</li>
</ol>

<h5>1.2.3 Spatial Noises</h5>
<ol>
  <li>a. It models the spatial dependencies in fMRI data: adjacent voxels are more correlated than those that are far apart;</li>
  <li>b . It could be modeled as (1) an AR correlation structure, (2) a Gaussian random
field, and (3) a Gamma random field.</li>
</ol>

<p>As an illustration, below on the left, we present a figure with task-based noise; and on the right, a 3-D view of a slide (20 by 20) of Gaussian random field spatial noises.</p>
<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/Task_based_noise.jpeg" alt="HTML5 Icon" style="height:200px;" />
    </a>
    <img src="/images/Gaussian_rf.jpg" alt="HTML5 Icon" style="height:200px;" />
</div>
</center>

<h4>Part 2: Parameter Specification</h4>
<p>Now that we understand the general mechanism of fMRI data generation, we need additional information such as when does the activation start for each experimental design, where does the activation occur in the brain, etc., in order to simulate real-life-like fMRI data. The additional information consists a few parameters:</p>
<li>onset time;</li>

<li>duration;</li>

<li>number of scans;</li>

<li>TR;</li>

<li>hrf;</li>

<li>effect size;</li>

<li>SNR;</li>

<li>noise type: low-frequency, physiological, task-related, mixture;</li>

<li>spatial noise: AR correlation, Gaussian random field, Gamma random field;</li>

<li>weights of each type of noise;</li>

<li>noise type: gaussian, rician;</li>

<li>the number of activated regions;</li>

<li>the coordinates of the regions;</li>

<li>the radius of the region;</li>

<li>the shape of the region (cube and sphere); and</li>

<li>other parameters</li>

<p><br /> Other useful packages includes:</p>

<li> Package: oro.nifti </li>
<p>write and read AFNI files;</p>

<h4>Part 3: Imaging Results</h4>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/fMRI_1.gif" alt="HTML5 Icon" style="width:128px;height:128px;" />
    </a>
    <img src="/images/fMRI_2.gif" alt="HTML5 Icon" style="width:128px;height:128px;" />
    <figcaption>Fig 1. Left: Raw fMRI; Right: Smoothed fMRI</figcaption>
</div>
</center>

<hr />

<!-- blog V -->
<h2>Get Started with SPM in Ten Steps</h2>

<p>Last updated: July 18, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>￼My dull brain was wrought. With things forgotten.</p>

– William Shakespeare

</div>

<p><br />
Many a friend of mine ask me about how to get started with Statistical Parametric Mapping (SPM) quickly. Being an R user primarily, I find myself incompetent to answer their question rigorously. However, as one of the most fundemental software in analyzing functional neuroimaging data, knowing how to use it - even moderately - has gained myself huge advantage in my research. Therefore, I present this post as a brief introductory guidance to readers who are new to SPM. Advanced readers may refer to <a href="http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf">SPM manual</a>. Readers interested in knowning more about fMRI data analysis may also find the book <a href="http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf">Principles of fMRI</a> and corresponding <a href="https://itunes.apple.com/us/book/statistical-analysis-fmri/id966384033?mt=13&amp;utm_medium=email&amp;utm_source=other&amp;utm_campaign=notifications.auto.faSP0XZhEeW75woKNsXkzw ">vedio lectures</a> by Professors Lindquist and Wager, and <a href="https://www.amazon.com/Handbook-Functional-MRI-Data-Analysis/dp/0521517664">Handbook of Functional MRI Data Analysis</a> by Professor Poldrack et al, helpful.</p>

<p><br />
Certainly, my experience with SPM is very limited; and likely I may present errors or omit important features of SPM in ten steps. I will update the following procedures regularly; if you have any suggestions, or criticisms, please <a href="mailto:olivery.chen@yahoo.com?Subject=fMRI%20code" target="_top">send me an email</a> to help me improve them.</p>

<p><br />
<b>Step 1:</b> Download <a href="http://www.mathworks.com/products/matlab/">Matlab</a>;
<br />
<b>Step 2:</b> Download <a href="http://www.fil.ion.ucl.ac.uk/spm/software/spm12/">SPM 12</a>;
<br /> 
<b>Step 3:</b> Open SPM in Matlab by entering <code>spm</code> in the command window. Based upon the data set you have (PET, EEG, or fMRI), click the corresponding icon (see Figure 1). Here, we choose fMRI, for example;</p>
<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/SPM_1.png" alt="HTML5 Icon" style="width:300px;" />
    </a>
    <img src="/images/SPM_2.png" alt="HTML5 Icon" style="width:300px;" />
</div>
</center>
<p><br />
<b>Step 4 (Display an image):</b> First, download desired datasets, which are usually stored in <code> NIfTi</code> (Neuroimaging Informatics Technology Initiative) files, saved in one <code>*.nii</code> file or a <code>*.hdr</code> and an <code>*.img</code> file. Functional images are saved as <code>fM*.image</code>; and structual images are saved as <code>sM*.image</code>. To display, click <code>Display &gt; file_location &gt; *.nii &gt; Done </code>. We see the display of a structual image (see Figure 2). 
<br />
<b>Step 5 (Preprocessing):</b> Preprocessing includes: motion correction; slice-time correction; coregistration; segmentation; normalization; and smoothing. These icons are in the top of the SPM menu (See the red frame in Figure 3). Let us take motion correction for example: <code> Realign &gt; Realign (Est &amp; Reg) &gt; Double click <i> Data &lt;- X </i> &gt; Double click <i> Session &lt;- X </i> </code>
<code> &gt; in the pop-up window choose desired file to be motion corrected &gt; Done &gt; click the green bottom </code> (See Figure 4). If inputing files are <code>sM*.image</code> (similar for functional images), resulting files are located in the original filepath as <code>meansM*.image</code> and <code>rsM*.image</code>. Similarily, for slice-timing, the input image is <code>rsM*.img</code> and the output image is <code>arsM*.img</code>; for coregistration, the input images are reference image <code>meansM*.img</code> and source image <code>sM*.img</code>, while the output image is updated “source image”; for segmentation, input image is <code>sM*.img</code> and the output images are <code>c1sMM*.img</code>, <code>c2sMM*.img</code>, and <code>sM*_seg_sn.img</code>; for normalization, the input images are <code>sM*.img</code> and <code>arsM*.img</code>, and the output image is <code>warsM*.img</code>; and finally, for smoothing, the input images are <code>warsM*.img</code> and <code>swarsM*.img</code>.</p>

<center>
<div id="top">
    <a id="logo" href="&lt;?php echo SITE_URL?&gt;" target="_blank">
        <img src="/images/SPM_3.png" alt="HTML5 Icon" style="width:300px;" />
    </a>
    <img src="/images/SPM_4.png" alt="HTML5 Icon" style="width:300px;" />
</div>
</center>

<hr />

<!-- blog II -->

<h2>Sir R. A. Fisher on Brain Science: a Neo-fictional Interpretation</h2>

<p>Last updated: June 1, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>Statistics may be regarded (i.) as the study of populations, (ii.) as the study of variation, (iii.) as the study of methods of the reduction of data.</p>

– Sir R. A. Fisher, Statistical Methods for Research Workers

</div>

<p><br />
<br /></p>

<p><br /> 
June 1, 1919.
<br /></p>

<p><br />
My name is Ronald Aylmer Fisher. I am a researcher at Rothamsted Experimental Station (the director here, Dr.<a href="https://en.wikipedia.org/wiki/E._John_Russell"> E. John Russell</a>, calls it Rothamsted Research for short) in Harpenden, a small town in the St Albans City district in the county of Hertfordshire, England. Here at Rothamsted Research, I analyze data obtained from crop experiments during the day. At night, I am working on a few manuscripts on experimental design and gathering several statistical methods to analyse variance in field studies. Two weeks ago, I paid a trip back to Cambridge and had a long discussion with my old boys <a href="https://en.wikipedia.org/wiki/John_Maynard_Keynes"> John Keynes</a>, <a href="https://en.wikipedia.org/wiki/Reginald_Punnett"> Reginald Punnett</a>, and <a href="https://en.wikipedia.org/wiki/Horace_Darwin"> Horace Darwin</a>, and have become very interested in studying data collected from the human brain. I would like to present a few thoughts sprung from our conversation. 
<br /></p>

<p><br />
I claim that the usefulness of statistics in neuroscience can be divided into three areas: the study of the brain in <strong>populations</strong>, (ii.) the study of <strong>variation</strong> of brain measurements in populations, and (iii.) the study of methods of the <strong>reduction of large brain data</strong>. I shall further expatiate these three areas by including statistical approaches with regards to data science development in neuroscience.
<br /></p>

<p><br /> 
First, the study of brain data is to gain insights to understanding how the brain perceives, processes, stores, and output information, in populations, or aggregates of individuals, rather than of individuals. The term population in brain science refers not only to an aggregate of brain activity measurements from multiple subjects, but also to an aggregate of a single brain measurement repeated multiple times for one subject. The former indicates our recognition of variations of brain activities amongst different individuals, whereas the latter represents our appreciation that the object of studying single subject brain activities is not to attempt to achieve an individual result, but rather, we make our best effort to ensure our findings representative. There are significant merits in studying data containing measurements of multiple subjects and those containing multiple measurements of single subjects. One of the end goals of brain science is to make scientific progress on diagnostics, treatments, cures and management of brain disorders. In order to raise the findings we have about the brain to the rank of science, we shall make statistical arguments about properties of the brain in a large aggregates of individuals. In order to produce treatments that target at a particular individual, we shall make statistical arguments about properties of the brain for that individual, based upon a large aggregates of measurements of his/her brain. Understanding how the brain works across subjects allows us to apply these principles at the individual level, and to advance applications that achieve artificial intelligence by mimicing the way an average brain performs, such as <a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html"> neural networks computers</a>. Understanding how the brain works at the individual level would assist us in understanding how a specific brain and its activities deviate from the average. It hence leads to scientific progress such as an introduction of personalized medical plans, and a usage of brain signals to identify a subject (See  <a href="http://www.nature.com/neuro/journal/v18/n11/abs/nn.4135.html"> Constable et al</a> and <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4216735/pdf/nihms-637906.pdf"> Wachinger et al</a>, among others). With an advancement of data acquisition technology and the popularization of high-performance computers, we are obtaining brain data in an unprecedentedly high-resolution, rapid, and accurate manner. Yet, there are strides to make. We shall advance our understanding of how the brain works in different types of populations: infants V.S. adults, females V.S. males, etc., how the brain signals change across time, and how brain signals change according to different (visual, auditory, sensory, etc.) inputs. Furthermore, we shall reduce the errors caused by measurement and data processing, via improving and developing proper statistical and computing techniques. Additionally, we shall aim to increase the sensitivity of our study. It allows pharmaceutical companies to develop affordable medicine that would treat specific brain disorders for the marjority of patients.
<br /></p>

<p><br /> 
Second, the brain is an extremely complicated organ stored in a blackbox. Despite the advance in brain science, little do we know about how information is processed in the box. For example, does the brain process information linearly, or more plausibly, non-linearly (but in which form)?; (b) there is a tremendous amount of variations amongst different brains in terms of sizes, volumes, shapes, etc; and (c) there is much variation in measuring brain signals. Whilist the first challenge is extensively tackled by physicists and computer scientists via the studying of dynamic systems, spiking neural networks, and other neural networks (e.g. <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>; <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">Boltzmann neural network</a>; <a href="https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks">deep neural networks</a>; <a href="http://www.sciencedirect.com/science/article/pii/S0169207004001116">adaptive neural networks</a>; <a href="https://en.wikipedia.org/wiki/Radial_basis_function_network">radial basis networks</a>), statisticians working on neuroscience are actively seeking to solve the latter two. Once we have identified our goal in studying the brain in populations, it is a natural follow-up to study variations because the brains in populations display vairation in one of more aspects. We, nevertheless, are not interested in variation of the brain <i>per se</i>; rather we recognize that variation is an inevitably troublesome by-product delineating circumstances where repeated measurements of the brain deviate from the average. Therefore, while describing the absolute properties of the brain (via parameters, e.g. mean activation intensity of a region of the brain), we encompass them with variances to address their uncertainty (and confidence). The introduction of variances leads to two further areas of statistical studies in brain science: the study of frequency distributions, and the study of correlations. The frequency distribution may be expressed as a mathematical function of the variate (e.g. voxel-specific t-statistic), either (i.) the proportion of the population (regions, voxels, neurons, etc.) for which the variate is less than a given value, or (ii.) by differentiating this function, the infinitesimal proportion of the population for which the variate falls within any infinitesimal element of its range. In brain science, many frequency distributions are heavy-tailed - hence the study of them has some implication in studying certain <a href="https://en.wikipedia.org/wiki/Financial_models_with_long-tailed_distributions_and_volatility_clustering">financial models</a>), and <i>vice versa</i>. On the other hand, we are not only interested in studying the variations of the parameters of interests at present, but also interested in estimating the quality and types of these variations. Especially, we are interested in examining the simultaneous variation among multiple variates. It, therefore, gives rise to the correlation analysis. For ultra-highdimensional brain data, however, a voxel-wise correlation analysis could be unmanageably troublesome. This leads to the following section.
<br /></p>

<p><br />
<img src="/images/decoding.jpg" alt="x" />
<br /></p>

<p><br /> 
The third usefulness of statistics in brain science is due to the practical need of reducing large bulks of data to a convenient amount that retains <i>relevant</i> information in the original data that our human minds (and our computer memories) are able to grasp, by means of a manageable anount of numerical values. How much data reduction, however, should we conduct? In all cases, it is possible to reduce data to a simple numerical form, or to an amount that our computers are able to efficiently handle, where, the reduced data are sufficient to shed light upon scientific questions the investigator has original in mind. In brain science, two widely-used approaches in conducting data reduction are (I) principal component analysis (PCA) and its variants and (II) assuming sparcity. The PCA method captures the marjority of the variation of the data. However, in brain science, oftentimes we have data with p ~ n or p » n, under which its estimates are inconsistent. There are a few papers on sparse PCA that have demonstrated subspace consistency. For example, <a href="http://projecteuclid.org/download/pdfview_1/euclid.aos/1368018173">Ma et al</a> and <a href="https://arxiv.org/pdf/0911.3827.pdf">Jung et al</a>. The sparcity assumption is, in essense, to make p &lt; n. It makes neurobiological sense in the following manner: the working brain consumes energy. At any given time, be it resting state or task state, only a portion of the neurons are activated so as to reserve energy. I had an amiable conversation with Professor <a href="http://www.jhsph.edu/faculty/directory/profile/323/pien-chien-huang">Pien-Chien Huang</a>, during which he mentioned that we human-beings do not dream in color (or at least have dreams less vivid and coloful). <a href="http://www.faculty.ucr.edu/~eschwitz/SchwitzPapers/DreamChina051031.htm">Schwitzgebel et al</a> has an article discussing this. I conjecture (with absence of scientific evidence) that a part of the reason is the brain attempts to reserve energy while sleeping (so only the minimal amount of information is processed: e.g. the brain only recalls the outlines, orientations, movements, etc. of objects. But they are sufficient to distiguish one from another and form visual events) - statistically a natural way of conducting data reduction! Much of the exisiting and on-going projects with regards to brain decoding, such as facial recognition and dream decoding, (see decoding simple pictures: <a href="http://haxbylab.dartmouth.edu/publications/HGF+01.pdf"> Haxby et al</a>, decoding objects with edges and orientations: <a href="http://www.nature.com/neuro/journal/v8/n5/full/nn1445.html"> Haynes and Rees </a> and <a href="http://www.nature.com/neuro/journal/v8/n5/full/nn1444.html"> Kamitani and Tong </a>, decoding complex picutres:<a href="http://gallantlab.org/_downloads/2009.Naselaris.etal.pdf"> Gallant et al </a>, decoding movies: <a href="https://www.youtube.com/watch?v=nsjDnYxJ0bo"> Gallant et al </a>, decoding intentions: <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.2011.05994.x/pdf"> Haynes et al </a>, and decoding dreams:<a href="http://science.sciencemag.org/content/340/6132/639"> Kamitani et al </a>) are mainly conducted using one or more of the following approaches: PCA, LASSO (sparcity assumption), and Bayesian analysis.
<br /></p>

<hr />

<!-- blog I -->
<h2>On Scientific Writing and Presentation</h2>

<p>Last updated: May 1, 2016</p>

<div style="background-color:black; color:white; padding:20px;">

<p>If you would not be forgotten as soon as you are dead, either write something worth reading or do things worth writing.</p>

- Benjamin Franklin

</div>

<p><br />
I have been long thinking about writing a blog that puts in order a few resources from which I have benefited immensely in my yet-immature-but-steadily-improving academic writing and presenting skills. On one hand, this project serves as a library to which I have a convenient access; on the other hand, I hope that some students like myself can benefit from reading these articles, essays, and blogs below. This is an on-going project; and the choice of resources purely subjective. Nonetheless, if you have any comment, or if you would like to recommend additional resources, please <a href="mailto:olivery.chen@yahoo.com?Subject=Comment%20on%20your%20blog" target="_top">send</a> me an email. Please check back every now and then as I update.
<br /></p>

<p><br /><a href="/files/doc/scientific_writing.pdf">This aritical</a> is recommended by Professor <a href="http://www-stat.wharton.upenn.edu/~buja">Andreas Buja</a> as “an article everybody should read” on scientific reading. Here is a <a href="/files/doc/summary.pdf">summary version</a> of it.
<br /></p>

<p><br /><a href="/files/doc/Style.pdf">The Elements of Style</a> teaches concise and vigorous English writing.
<br /></p>

<p><br />Professor <a href="http://jtleek.com">Jeff Leek</a> gives good advice on effective presentation <a href="/files/doc/Presentation_Leek.pdf">here</a>.
<br /></p>

<p><br />As a student studying in the interdisciplinary field between statistics, computer science, and neurosicence, I have learned a great deal from reading the works of Sir R. A. Fisher’s, inter alia, the <em>“Statistical Trilogy”</em> : (1) <a href="/files/doc/Fisher_1.pdf">Statisticcal Methods for Research Workers</a>; (2) <a href="/files/doc/Fisher_2.pdf">The Design of Experiments</a>; and (3) <a href="http://www.amazon.com/Statistical-Methods-Scientific-Inference-Ronald/dp/0028447409">Statistical Methods and Scientific Inference</a>
<br /></p>

<p><br />In the <a href="https://archive.org/details/autobiography00franuoft">Autobiography of Benjamin Franklin</a>,  Mr. Franklin taught us a few procedures to improve writing:</p>
<li> Read an article </li>
<li> Write short hints about each sentence (you could also outline the piece) and set it aside for awhile </li>
<li> Rewrite the article in his own words</li>
<li> Compare with the original, and</li>
<li> Revise and improve your essay.</li>
<p><br /></p>

<p><br /> <a href="http://www.hopkinsmedicine.org/otolaryngology/our_team/residents_fellows.html">Andrew Lee</a>, MD, my former roommate, an ENT resident at the Johns Hopkins Hospital, and an excellent writer, suggests that the most effective thing to do to improve one’s writing skills is to read essays; and read them <b>critically</b>. “By critically”, Andrew elaborates, “I mean while reading, think why does the author choose that particular word, and what does that word do?” To highlight the importance of effective writing, I once asked Andrew to read an email of mine in response to a job application, which seemed to be on the verge of a declination at that time. He rewrote the email and got me the job. He did not change the context of the communication; but he carefully changed a few words, which improved the presentation drastically. Here is a list of resources he suggests to read:</p>

<li> <a href="http://www.theatlantic.com">The Atlantic</a> </li>
<li> <a href="http://www.economist.com">The Economist</a> </li>
<li> <a href="http://topics.nytimes.com/top/opinion/editorialsandoped/editorials/index.html">The New York Times Editorials</a></li>
<li> <a href="/files/doc/Great_Expectations.pdf">Great Expectation</a>, by Charles Dickens</li>
<li> <a href="/files/doc/Crime_and_Punishment.pdf">Crime and Punishment</a>, by Fyodor Dostoevsky </li>
<li> <a href="/files/doc/Catch_22.pdf">Catch 22</a>, by Joseph Heller </li>
<li> <a href="/files/doc/Wuthering_Heights.pdf">Wuthering Heights</a>, by Emily Bronte</li>
<li> <a href="/files/doc/Heart_of_Darkness.pdf">Heart of Darkness</a>, by Joseph Conrad</li>
<li> <a href="/files/doc/Beloved.pdf">Beloved</a>, by Toni Morrison</li>
<li> <a href="/files/doc/The_sound_and_the_fury.pdf">The Sound and the Fury</a>, by William Faulkner</li>
<p><br /></p>


      
        <hr />
        
      
    </div><!-- /.article-wrap -->
    
  </article>
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    

<!-- 
<span>&copy; 2016 Oliver Y. Chén. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>
-->
  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://oliverychen.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://oliverychen.github.io/assets/js/scripts.min.js"></script>

          

</body>
</html>